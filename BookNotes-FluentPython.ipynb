{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Zen of Python\n",
    "\n",
    "https://github.com/fluentpython\n",
    "\n",
    "http://www.pythontutor.com/visualize.html#mode=display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magic and dunder\n",
    "The term magic method is slang for special method, but when talk‐ ing about a specific method like __getitem__, some Python devel‐ opers take the shortcut of saying “under-under-getitem” which is ambiguous, since the syntax __x has another special meaning2. But being precise and pronouncing “under-under-getitem-under- under” is tiresome, so I follow the lead of author and teacher Steve Holden and say “dunder-getitem”. All experienced Pythonistas un‐ derstand that shortcut. As a result, the special methods are also known as dunder methods 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## namedtuple\n",
    "The first thing to note is the use of collections.namedtuple to construct a simple class to represent individual cards. Since Python 2.6, namedtuple can be used to build classes of objects that are just bundles of attributes with no custom methods, like a database record. In the example we use it to provide a nice representation for the cards in the deck, as shown in the console session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Card(rank='7', suit='diamonds')\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "Card = collections.namedtuple('Card', ['rank', 'suit'])\n",
    "beer_card = Card('7', 'diamonds')\n",
    "print(beer_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Card(rank='9', suit='diamonds')\n",
      "Card(rank='J', suit='diamonds')\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "Card = collections.namedtuple('Card', ['rank', 'suit'])\n",
    "class FrenchDeck:\n",
    "    ranks = [str(n) for n in range(2, 11)] + list('JQKA') \n",
    "    suits = 'spades diamonds clubs hearts'.split()\n",
    "   \n",
    "    def __init__(self):\n",
    "        self._cards = [Card(rank, suit) for suit in self.suits for rank in  self.ranks]\n",
    "    def __len__(self):\n",
    "        return len(self._cards)\n",
    "    def __getitem__(self, position): \n",
    "        return self._cards[position]\n",
    "                       \n",
    "from random import choice \n",
    "deck = FrenchDeck()\n",
    "print(choice(deck)) \n",
    "print(choice(deck))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __str__ vs __repr__\n",
    "\n",
    "http://stackoverflow.com/questions/1436703/difference-between-str-and-repr-in-python\n",
    "\n",
    "Alex summarized well but, surprisingly, was too succinct.\n",
    "\n",
    "First, let me reiterate the main points in Alex’s post:\n",
    "\n",
    "The default implementation is useless (it’s hard to think of one which wouldn’t be, but yeah)\n",
    "__repr__ goal is to be unambiguous\n",
    "__str__ goal is to be readable\n",
    "Container’s __str__ uses contained objects’ __repr__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python data model\n",
    "https://docs.python.org/3/reference/datamodel.html\n",
    "\n",
    "\n",
    "\n",
    "__bool__\n",
    "__add__\n",
    "__mul__\n",
    "__getitem__\n",
    "__repr__   (%r) to look vector like Vector(2, 3) - unambigious\n",
    "__str__ (%s) to look vector like Vector(\"2\", \"3\")- readable\n",
    "\n",
    "string/bytes representation conversion to number\n",
    "emulating collections\n",
    "iteration\n",
    "emulating callables\n",
    "context management\n",
    "instance creation and destruction attribute management\n",
    "attribute descriptors class services\n",
    "method names\n",
    "__repr__, __str__, __format__, __bytes__\n",
    "__abs__, __bool__, __complex__, __int__, __float__, __hash__, __in\n",
    "dex__\n",
    "__len__, __getitem__, __setitem__, __delitem__, __contains__ __iter__, __reversed__, __next__\n",
    "__call__\n",
    "__enter__, __exit__\n",
    "__new__, __init__, __del__\n",
    "__getattr__, __getattribute__, __setattr__, __delattr__, __dir__ __get__, __set__, __delete__\n",
    "__prepare__, __instancecheck__, __subclasscheck__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List comprehensions and generator expressions\n",
    "For brevity, many Python programmers call list comprehensions list‐ comps, and generator expressions genexps. I will use these words as well.\n",
    "A for loop may be used to do lots of different things: scanning a sequence to count or pick items, computing aggregates (sums, averages), or any number of other processing. The code in Example 2-1 is building up a list. In contrast, a listcomp is meant to do one thing only: to build a new list.\n",
    "Of course, it is possible to abuse list comprehensions to write truly incomprehensible code. I’ve seen Python code with listcomps used just to repeat a block of code for its side effects. Please don’t use that syntax if you are not doing something with the produced list. Also, try to keep it short. If the list comprehension spans more than two lines, it is probably best to break it apart or rewrite as a plain old for loop. Use your best judgment: for Python as for English, there are no hard and fast rules for clear writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36, 162, 163, 165, 8364, 164]\n",
      "[36, 162, 163, 165, 8364, 164]\n"
     ]
    }
   ],
   "source": [
    "symbols = '$¢£¥€¤'\n",
    "codes = []\n",
    "for symbol in symbols:\n",
    "    codes.append(ord(symbol))\n",
    "print(codes)\n",
    "\n",
    "print([ord(symbol) for symbol in symbols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, imagine you need to produce a list of t-shirts available in two colors and three sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('black', 'S'), ('black', 'M'), ('black', 'L'), ('white', 'S'), ('white', 'M'), ('white', 'L')]\n"
     ]
    }
   ],
   "source": [
    "colors = ['black', 'white']\n",
    "sizes = ['S', 'M', 'L']\n",
    "tshirts = [ (color, size) for color in colors for size in sizes]\n",
    "print(tshirts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listcomps are a one-trick pony: they build lists. To fill-up other sequence types, a genexp is the way to go. The next section is a brief look at genexps in the context of building non-list sequences.\n",
    "\n",
    "uses a genexp with a cartesian product to print out a roster of t-shirts of two colors in three sizes. In contrast with Example 2-4, here the 6-item list of t-shirts is never built in memory: the generator expression feeds the for loop producing one item at a time. If the two lists used in the cartesian product had a thousand items each, using\n",
    "\n",
    "a generator expression would save the expense of building a list with a million items just to feed the for loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tuples\n",
    "Tuples are not just immutable lists\n",
    "Some introductory texts about Python present tuples as “immutable lists”, but that is short selling them. Tuples do double-duty: they can be used as immutable lists and also as records with no field names. This use is sometimes overlooked, so we will start with that.\n",
    "\n",
    "Tuples hold records: each item in the tuple holds the data for one field and the position of the item gives its meaning.\n",
    "If you think of a tuple just as an immutable list, the quantity and the order of the items may or may not be important, depending on the context. But when using a tuple as a collection of fields, the number of items is often fixed and their order is always vital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo\n"
     ]
    }
   ],
   "source": [
    "city, year, pop, chg, area = ('Tokyo', 2003, 32450, 0.66, 8014)\n",
    "print(city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most visible form of tuple unpacking is parallel assignment, that is, assigning items from an iterable to a tuple of variables, as you can see in this example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.9425/-118.408056\n"
     ]
    }
   ],
   "source": [
    "lax_coordinates = (33.9425, -118.408056)\n",
    "latitude, longitude = lax_coordinates\n",
    "print(latitude,longitude, sep='/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An elegant application of tuple unpacking is swapping the values of variables without using a temporary variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 10\n"
     ]
    }
   ],
   "source": [
    "a= 10\n",
    "b=20\n",
    "a,b = b,a\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example of tuple unpacking is prefixing an argument with a star when calling\n",
    "a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2\n"
     ]
    }
   ],
   "source": [
    "divmod(20, 8)\n",
    "t=(20,3)\n",
    "divmod(*t)\n",
    "quotient, remainder = divmod(*t)\n",
    "print(quotient,remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above also shows a further use of tuple unpacking: enabling functions to return multiple values in a way that is convenient to the caller. For example, the os.path.split() function builds a tuple (path, last_part) from a filesystem path\n",
    "\n",
    "Sometimes when we only care about certain parts of a tuple when unpacking, a dummy variable like _ is used as placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idrsa.pub\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "_, filename = os.path.split('/home/luciano/.ssh/idrsa.pub')\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Defining function parameters with *args to grab arbitrary excess arguments is a classic Python feature.\n",
    "In Python 3 this idea was extended to apply to parallel assignment as well\n",
    "\n",
    "In the context of parallel assignment, the * prefix can be applied to exactly one variable, but it can appear in any position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "a, b, *rest = range(5)\n",
    "print(rest)\n",
    "\n",
    "a, *body, c, d = range(5)\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Namedtuple\n",
    "As designed, tuples are very handy. But there is a missing feature when using them as records: sometimes it is desirable to name the fields. That is why the namedtuple func‐ tion was invented. \n",
    "\n",
    "the collections.namedtuple function is a factory that produces subclasses of tuple enhanced with field names and a class name — which helps debugging\n",
    "\n",
    "Instances of a class that you build with namedtuple take exactly the same amount of memory as tuples because the field names are stor‐ ed in the class. They use less memory than a regular object because they do store attributes in a per-instance __dict__.\n",
    "\n",
    "1.Two parameters are required to create a named tuple: a class name and a list of field names, which can be given as an iterable of strings or as a single space- delimited string.\n",
    "\n",
    "2.Data must be passed as positional arguments to the constructor (in contrast, the tuple constructor takes a single iterable).\n",
    "\n",
    "3.You can access the fields by name or position.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.933"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "# City = namedtuple('City', 'name country population coordinates')  both versions can be used\n",
    "City = namedtuple('City', ['name', 'country', 'population' ,'coordinates'])\n",
    "tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139.691667))\n",
    "tokyo.population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1._fields is a tuple with the field names of the class.\n",
    "\n",
    "2._make() lets you instantiate a named tuple from an iterable; City(*delhi_da\n",
    "ta) would do the same.\n",
    "\n",
    "3._asdict() returns a collections.OrderedDict built from the named tuple\n",
    "instance. That can be used to produce a nice display of city data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('name', 'Delhi NCR'),\n",
       "             ('country', 'IN'),\n",
       "             ('population', 21.935),\n",
       "             ('coordinates', LatLong(lat=28.613889, long=77.208889))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "City._fields\n",
    "LatLong = namedtuple('LatLong', 'lat long')\n",
    "delhi_data = ('Delhi NCR', 'IN', 21.935, LatLong(28.613889, 77.208889))\n",
    "delhi = City._make(delhi_data)\n",
    "delhi._asdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building lists of lists\n",
    "Sometimes we need to initialize a list with a certain number of nested lists, for example, to distribute students in a list of teams or to represent squares on a game board. The best way of doing so is with a list comprehension, like this\n",
    "\n",
    "Create a list of with 3 lists of 3 items each. Inspect the structure. Place a mark in row 1, column 2 and check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['_', '_', '_'], ['_', '_', 'X'], ['_', '_', '_']]\n"
     ]
    }
   ],
   "source": [
    "board = [['_'] * 3 for i in range(3)]\n",
    "board[1][2] = 'X'\n",
    "print(board)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outer list is made of three references to the same inner list. While it is unchanged, all seems right.\n",
    "Placing a mark in row 1, column 2 reveals that all rows are aliases referring to the same object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['_', '_', 'X'], ['_', '_', 'X'], ['_', '_', 'X']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_board = [['_'] * 3] * 3\n",
    "weird_board[1][2]='X'\n",
    "weird_board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above code works like below so same row gets repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = ['_'] * 3 \n",
    "board = []\n",
    "for i in range(3):\n",
    "    board.append(row)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = []\n",
    "for i in range(3):\n",
    "    row = ['_'] * 3\n",
    "    board.append(row)\n",
    "board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries\n",
    "### Hashable\n",
    "An object is hashable if it has a hash value which never changes during its lifetime (it needs a __hash__() method), and can be compared to other objects (it needs an __eq__() method). Hashable objects which compare equal must have the same hash value. [...]\n",
    "\n",
    "The atomic immutable types (str, bytes, numeric types) are all hashable. A frozen set is always hashable, because its elements must be hashable by definition. A tuple is hashable only if all its items are hashable. See tuples tt, tl and tf:\n",
    "\n",
    "At this writing the Python Glossary states: “All of Python’s im‐ mutable built-in objects are hashable” but that is inaccurate be‐ cause a tuple is immutable, yet it may contain references to unhashable objects.\n",
    "\n",
    "User-defined types are hashable by default because their hash value is their id() and they all compare not equal. If an object implements a custom __eq__ that takes into account its internal state, it may be hashable only if all its attributes are immutable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8027212646858338501"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = (1, 2, (30, 40))\n",
    "hash(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = dict(one=1, two=2, three=3)\n",
    "b = {'one': 1, 'two': 2, 'three': 3}\n",
    "c = dict(zip(['one', 'two', 'three'], [1, 2, 3]))\n",
    "d = dict([('two', 2), ('one', 1), ('three', 3)])\n",
    "e = dict({'three': 3, 'one': 1, 'two': 2})\n",
    "a == b == c == d == e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dict comprehensions\n",
    "Since Python 2.7 the syntax of listcomps and genexps was applied to dict comprehen‐ sions (and set comprehensions as well, which we’ll soon visit). A dictcomp builds a dict instance by producing key:value pair from any iterable.\n",
    "\n",
    "If you’re used to liscomps, dictcomps are a natural next step. If you aren’t, the spread of the listcomp syntax means it’s now more profitable than ever to become fluent in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{81: 'JAPAN',\n",
       " 86: 'CHINA',\n",
       " 91: 'INDIA',\n",
       " 92: 'PAKISTAN',\n",
       " 234: 'NIGERIA',\n",
       " 880: 'BANGLADESH'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIAL_CODES = [\n",
    " (86, 'China'),\n",
    " (91, 'India'),\n",
    " (1, 'United States'),\n",
    " (62, 'Indonesia'),\n",
    " (55, 'Brazil'),\n",
    " (92, 'Pakistan'),\n",
    " (880, 'Bangladesh'),\n",
    " (234, 'Nigeria'),\n",
    " (7, 'Russia'),\n",
    " (81, 'Japan'),\n",
    " ]\n",
    "country_code = {country: code for code, country in DIAL_CODES}\n",
    "{code: country.upper() for country, code in country_code.items() if code > 80}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defaultdict: another take on missing keys\n",
    "Here is how it works: when instantiating a defaultdict, you provide a callable which is used to produce a default value whenever __getitem__ is passed a non-existent key argument.\n",
    "For example, given an empty defaultdict created as dd = defaultdict(list), if 'new-key' is not in dd then the expression dd['new-key'] does the following steps:\n",
    "1. calls list() to create a new list;\n",
    "2. inserts the list into dd using 'new-key' as key;\n",
    "3. returns a reference to that list.\n",
    "The callable that produces the default values is held in an instance attribute called default_factory.\n",
    "\n",
    "* Create a defaultdict with the list constructor as default_factory.\n",
    "* If word is not initially in the index, the default_factory is called to produce the missing value, which in this case is an empty list that is then assigned to index[word] and returned, so the .append(location) operation always succeeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import re\n",
    "# import collections\n",
    "# WORD_RE = re.compile('\\w+')\n",
    "# index = collections.defaultdict(list)\n",
    "# with open(sys.argv[1], encoding='utf-8') as fp:\n",
    "#     for line_no, line in enumerate(fp, 1): \n",
    "#         for match in WORD_RE.finditer(line):\n",
    "#                 word = match.group()\n",
    "#                 column_no = match.start()+1\n",
    "#                 location = (line_no, column_no)\n",
    "#                 index[word].append(location)\n",
    "# # print in alphabetical order\n",
    "# for word in sorted(index, key=str.upper): \n",
    "#     print(word, index[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no default_factory is provided, the usual KeyError is raised for missing keys.\n",
    "The default_factory of a defaultdict is only invoked to provide default values for __getitem__ calls, and not for the other meth‐ ods. For example, if dd is a defaultdict, and k is a missing key, dd[k] will call the default_factory to create a default value, but dd.get(k) still returns None.\n",
    "\n",
    "The mechanism that makes defaultdict work by calling default_factory is actually the __missing__ special method, a feature supported by all standard mapping types that we discuss next.\n",
    "\n",
    "Underlying the way mappings deal with missing keys is the aptly named __missing__ method. This method is not defined in the base dict class, but dict is aware of it: if you subclass dict and provide a __missing__ method, the standard dict.__getitem__ will call it whenever a key is not found, instead of raising KeyError.\n",
    "\n",
    "The __missing__ method is just called by __getitem__, i.e. for the d[k] operator. The presence of a __missing__ method has no ef‐ fect on the behavior of other methods that look up keys, such as get or __contains__ (which implements the in operator). This is why the default_factory of defaultdict works only with __geti tem__, as noted in the warning at the end of the previous section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import builtins\n",
    "from collections import ChainMap\n",
    "pylookup = ChainMap(locals(), globals(), vars(builtins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collections.OrderedDict\n",
    "maintains keys in insertion order, allowing iteration over items in a predictable order. The popitem method of an OrderedDict pops the first item by default, but if called as my_odict.popitem(last=True), it pops the last item added.\n",
    "### collections.ChainMap\n",
    "holds a list of mappings which can be searched as one. The lookup is performed on each mapping in order, and succeeds if the key is found in any of them. This is useful to interpreters for languages with nested scopes, where each mapping represents a scope context. The ChainMap section in the collections docs has several examples of ChainMap usage, including this snippet inspired by the basic rules of variable lookup in Python:\n",
    "import builtins\n",
    "pylookup = ChainMap(locals(), globals(), vars(builtins))\n",
    "### collections.Counter\n",
    "a mapping that holds an integer count for each key. Updating an existing key adds to its count. This can be used to count instances of hashable objects (the keys) or as a multiset — a set that can hold several occurrences of each element. Counter implements the + and - operators to combine tallies, and other useful methods such as most_common([n]), which returns an ordered list of tuples with the n most com‐ mon items and their counts; see the documentation. Here is Counter used to count letters in words:\n",
    "``` \n",
    "ct = collections.Counter('abracadabra')\n",
    "ct\n",
    "Counter({'a': 5, 'b': 2, 'r': 2, 'c': 1, 'd': 1}) >>> ct.update('aaaaazzz')\n",
    "ct\n",
    "Counter({'a': 10, 'z': 3, 'b': 2, 'r': 2, 'c': 1, 'd': 1}) >>> ct.most_common(2)\n",
    "[('a', 10), ('z', 3)] ```\n",
    "\n",
    "### collections.UserDict\n",
    "a pure Python implementation of a mapping that works like a standard dict.\n",
    "While OrderedDict, ChainMap and Counter come ready to use, UserDict is designed to be subclassed, as we’ll do next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subclassing UserDict\n",
    "\n",
    "It’s almost always easier to create a new mapping type by extending UserDict than dict. Its value can be appreciated as we extend our StrKeyDict0 from Example 3-7 to make sure that any keys added to the mapping are stored as str.\n",
    "The main reason why it’s preferable to subclass from UserDict than dict is that the built-in has some implementation shortcuts that end up forcing us to override methods that we can just inherit from UserDict with no problems4.\n",
    "Note that UserDict does not inherit from dict, but has an internal dict instance, called data, which holds the actual items. This avoids undesired recursion when coding special methods like __setitem__, and simplifies the coding of __contains__, compared to Example 3-7.\n",
    "Thanks to UserDict, StrKeyDict (Example 3-8) is actually shorter than StrKeyDict0 (Example 3-7), but it does more: it stores all keys as str, avoiding unpleasant surprises if the instance is built or updated with data containing non-string keys.\n",
    "Example 3-8. StrKeyDict always converts non-string keys to str — on insertion, up‐ date and lookup.\n",
    "```\n",
    "import collections\n",
    "class StrKeyDict(collections.UserDict):\n",
    "    def __missing__(self, key): \n",
    "        if isinstance(key, str):\n",
    "            raise KeyError(key) \n",
    "        return self[str(key)]\n",
    "    def __contains__(self, key): \n",
    "        return str(key) in self.data\n",
    "    def __setitem__(self, key, item): \n",
    "        self.data[str(key)] = item```\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set theory\n",
    "Sets are a relatively new addition in the history of Python, and somewhat underused. The set type and its immutable sibling frozenset first appeared in a module in Python 2.3 and were promoted to built-ins in Python 2.6.\n",
    "In this book, the word “set” is used to refer both to set and frozen set. When talking specifically about the set class, its name appears in the constant width font used for source code: set.\n",
    "Set elements must be hashable. The set type is not hashable, but frozenset is, so you can have frozenset elements inside a set.\n",
    "In addition to guaranteeing uniqueness, the set types implement the essential set oper‐ ations as infix operators, so, given two sets a and b, a | b returns their union, a & b computes the intersection, and a - b the difference. Smart use of set operations can reduce both the line count and the run time of Python programs, at the same time making code easier to read and reason about — by removing loops and lots of condi‐ tional logic.\n",
    "For example, imagine you have a large set of e-mail addresses (the haystack) and a smaller set of addresses (the needles) and you need to count how many of the nee dles occur in the haystack. Thanks to set intersection (the & operator) you can code that in a simple line:\n",
    "\n",
    "The syntax of set literals — {1}, {1, 2}, etc. — looks exactly like the math notation, with one important exception: there’s no literal notation for the empty set, we must remember to write set().\n",
    "Syntax quirk\n",
    "```Don’t forget: to create an empty set, use the constructor without an argument: set(). If you write {}, you’re creating an empty dict — this hasn’t changed.```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash tables in dictionaries\n",
    "This is a high level view of how Python uses a hash table to implement a dict. Many details are omitted — the CPython code has some optimization tricks6 — but the overall description is accurate.\n",
    "A hash table is a sparse array, i.e. an array which always has empty cells. In standard data structure texts, the cells in a hash table are often called “buckets”. In a dict hash table, there is a bucket for each item, and it contains two fields: a reference to the key and a reference to the value of the item. Because all buckets have the same size, access to an individual bucket is done by offset.\n",
    "Python tries to keep at least 1/3 of the buckets empty; if the hash table becomes too crowded, it is copied to a new location with room for more buckets.\n",
    "To put an item in a hash table the first step is to calculate the hash value of the item key, which is done with the hash() built-in function, explained next.\n",
    "\n",
    "### Hashes and equality\n",
    "The hash() built-in function works directly with built-in types and falls back to calling __hash__ for user-defined types. If two objects compare equal, their hash values must also be equal, otherwise the hash table algorithm does not work. For example, because 1 == 1.0 is true, hash(1) == hash(1.0) must also be true, even though the internal representation of an int and a float are very different7.\n",
    "\n",
    "### The hash table algorithm\n",
    "To fetch the value at my_dict[search_key], Python calls hash(search_key) to obtain the hash value of search_key and uses the least significant bits of that number as an offset to look up a bucket in the hash table (the number of bits used depends on the current size of the table). If the found bucket is empty, KeyError is raised. Otherwise, the found bucket has an item — a found_key:found_value pair — and then Python\n",
    "checks whether search_key == found_key. If they match, that was the item sought: found_value is returned.\n",
    "However, if search_key and found_key do not match, this is a hash collision. This hap‐ pens because a hash function maps arbitrary objects to a small number of bits, and — in addition — the hash table is indexed with a subset of those bits. To resolve the colli‐ sion, the algorithm then takes different bits in the hash, massages them in a particular way and uses the result as an offset to look up a different bucket8. If that is empty, KeyError is raised; if not, either the keys match and the item value is returned, or the collision resolution process is repeated. See Figure 3-3 for a diagram of this algorithm.\n",
    "\n",
    "The process to insert or update an item is the same, except that when an empty bucket is located, the new item is put there, and when a bucket with a matching key is found, the value in that bucket is overwritten with the new value.\n",
    "Additionally, when inserting items Python may determine that the hash table is too crowded and rebuild it to a new location with more room. As the hash table grows, so does the number of hash bits used as bucket offsets, and this keeps the rate of collisions low.\n",
    "\n",
    "**Note : The C function that shuffles the hash bits in case of collision has a curious name: perturb. See dictob ject.c in the CPython source code for all the details.\n",
    "\n",
    "this implementation may seem like a lot of work, but even with millions of items in a dict, many searches happen with no collisions, and the average number of collisions per search is between one and two. Under normal usage, even the unluckiest keys can be found after a handful of collisions are resolved.\n",
    "Knowing the internals of the dict implementation we can explain the strengths and limitations of this data structure and all the others derived from it in Python. We are now ready to consider why Python dict behave as they do.\n",
    "\n",
    "### Practical consequences of how dict works\n",
    "In the next five sections, we’ll discuss the limitations and benefits that the underlying\n",
    "hash table implementation brings to dict usage. \n",
    "#1: Keys must be hashable objects\n",
    "An object is hashable if all of these requirements are met:\n",
    "1. It supports the hash() function via a __hash__() method that always returns the same value over the lifetime of the object.\n",
    "2. It supports equality via an __eq__() method.\n",
    "3. If a == b is True then hash(a) == hash(b) must also be True.\n",
    "User-defined types are hashable by default because their hash value is their id() and they all compare not equal.\n",
    "\n",
    "if you implement a class with a custom __eq__ method then you must also implement a suitable __hash__, because you must always make sure that if a == b is True then hash(a) == hash(b) is also True. Otherwise you are breaking an invariant of the hash table algorithm, with the grave consequence that dicts and sets will not deal reliably with your objects. If a custom __eq__ depends on mu‐ table state, then __hash__ must raise TypeError with a message like unhashable type: 'MyClass'.\n",
    "\n",
    "#2: dicts have significant memory overhead\n",
    "\n",
    "Because a dict uses a hash table internally, and hash tables must be sparse to work, they are not space efficient. For example, if you are handling a large quantity of records it makes sense to store them in a list of tuples or named tuples instead of using a list of dictionaries in JSON style, with one dict per record. Replacing dicts with tuples reduces the memory usage in two ways: by removing the overhead of one hash table per record and by not storing the field names again with each record.\n",
    "\n",
    "For user-defined types, the __slots__ class attribute changes the storage of instance attributes from a dict to a tuple in each instance. This will be discussed in “Saving space with the __slots__ class attribute” on page 265 (Chapter 9).\n",
    "Keep in mind we are talking about space optimizations. If you are dealing with a few million objects and your machine has gigabytes of RAM, you should postpone such optimizations until they are actually warranted. Optimization is the altar where main‐ tainability is sacrificed.\n",
    "\n",
    "#3: Key search is very fast\n",
    "\n",
    "The dict implementation is an example of trading space for time: dictionaries have significant memory overhead, but they provide fast access regardless of the size of the dictionary — as long as it fits in memory. As Table 3-5 shows, when we increased the size of a dict from 1,000 to 10,000,000 elements, the time to search grew by a factor of 2.8, from 0.000163s to 0.000456s. The latter figure means we could search more than 2 million keys per second in a dict with 10 million items.\n",
    "\n",
    "\n",
    "#4: Key ordering depends on insertion order\n",
    "\n",
    "When a hash collision happens, the second key ends up in a position that it would not normallyoccupyifithadbeeninsertedfirst.So,adictbuiltasdict([(key1, value1), (key2, value2)]) compares equal to dict([(key2, value2), (key1, value1)]), but their key ordering may not be the same if the hashes of key1 and key2 collide.\n",
    "\n",
    "#5: Adding items to a dict may change the order of existing keys\n",
    "\n",
    "Whenever you add a new item to a dict, the Python interpreter may decide that the hash table of that dictionary needs to grow. This entails building a new, bigger hash table, and adding all current items to the new table. During this process, new (but different) hash collisions may happen, with the result that the keys are likely to be or‐ dered differently in the new hash table. All of this is implementation-dependent, so you cannot reliably predict when it will happen. If you are iterating over the dictionay keys and changing them at the same time, your loop may not scan all the items as expected — not even the items that were already in the dictionary before you added to it.\n",
    "This is why modifying the contents of a dict while iterating through it is a bad idea. If you need to scan and add items to a dictionary, do it in two steps: read the dict from start to finish and collect the needed additions in a second dict. Then update the first one with it.\n",
    "\n",
    "### How sets work — practical consequences\n",
    "\n",
    "The set and frozenset types are also implemented with a hash table, except that each bucket holds only a reference to the element (as if it were a key in a dict, but without a value to go with it). In fact, before set was added to the language, we often used dictionaries with dummy values just to perform fast membership tests on the keys.\n",
    "Everything said in “Practical consequences of how dict works” on page 90 about how the underlying hash table determines the behavior of a dict applies to a set. Without repeating the previous section, we can summarize it for sets with just a few words:\n",
    "1. Set elements must be hashable objects.\n",
    "2. Sets have a significant memory overhead.\n",
    "3. Membership testing is very efficient.\n",
    "4. Element ordering depends on insertion order.\n",
    "5. Adding elements to a set may change the order of other elements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Functions in Python are first-class objects. Programming language theorists define a “first-class object” as a program entity that can be:\n",
    "* created at runtime;\n",
    "* assigned to a variable or element in a data structure;\n",
    "* passed as an argument to a function;\n",
    "* returned as the result of a function.\n",
    "\n",
    "Integers, strings and dictionaries are other examples of first-class objects in Python — nothing fancy here. But, if you came to Python from a language where functions are not first-class citizens, this chapter and the rest of Part III of the book focuses on the implications and practical applications of treating functions as objects.\n",
    "\n",
    "The term “first-class functions” is widely used as shorthand for “functions as first class objects”. It’s not perfect because it seems to imply an “elite” among functions. In Python, all functions are first-class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['banana', 'apple', 'fig', 'raspberry', 'strawberry', 'cherry']\n",
      "Help on function factorial in module __main__:\n",
      "\n",
      "factorial(n)\n",
      "    returns n!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def factorial(n):\n",
    "    '''returns n!'''\n",
    "    return 1 if n < 2 else n * factorial(n-1)\n",
    "factorial.__doc__\n",
    "factorial.__class__\n",
    "\n",
    "type(factorial)\n",
    "\n",
    "factorial(42)\n",
    "\n",
    "fact = factorial\n",
    "fact(4)\n",
    "\n",
    "list(map(factorial, range(11)))\n",
    "\n",
    "fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana']\n",
    "sorted(fruits, key=len)\n",
    "\n",
    "def reversed(word):\n",
    "    return word[::-1]\n",
    "\n",
    "print(sorted(fruits, key=reversed))\n",
    "help(factorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not palindrome\n",
      "palindrome\n",
      "palindrome\n",
      "palindrome\n"
     ]
    }
   ],
   "source": [
    "def reverse(str):\n",
    "    return str[::-1]\n",
    "\n",
    "def palindrome(word):\n",
    "    word = word.upper()\n",
    "    if word == word[::-1]:\n",
    "        print(\"palindrome\")\n",
    "    else:\n",
    "        print(\"Not palindrome\")\n",
    "\n",
    "palindrome(\"Mahesh\")\n",
    "palindrome(\"Mom\")\n",
    "palindrome(\"Rotator\")\n",
    "palindrome(\"Anna\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher-order functions\n",
    "A function that takes a function as argument or returns a function as result is a higher- order function. One example is map, shown in Example 5-2. Another is the sorted built- in function: an optional key argument lets you provide a function to be applied to each item for sorting\n",
    "\n",
    "In the functional programming paradigm, some of the best known higher-order func‐ tions are map, filter, reduce and apply. The apply function was deprecated in Python 2.3 and removed in Python 3 because it’s no longer necessary. If you need to call a function with a dynamic set of arguments, you can just write fn(*args, **key words) instead of apply(fn, args, kwargs).\n",
    "The map, filter and reduce higher-order functions are still around, but better alter‐ natives are available for most of their use cases, as the next section shows.\n",
    "\n",
    "Functional languages commonly offer the map, filter and reduce higher-order func‐ tions (sometimes with different names). The map and filter functions are still built- ins in Python 3, but since the introduction of list comprehensions and generator ex‐ pressions, they are not as important. A listcomp or a genexp does the job of map and filter combined, but is more readable. \n",
    "\n",
    "In Python 3, map and filter return generators — a form of iterator — so their direct substitute is now a generator expression (in Python 2 these functions returned lists, therefore their closest alternative is a listcomp).\n",
    "The reduce function was demoted from a built-in in Python 2 to the functools module in Python 3. Its most common use case, summation, is better served by the sum built- in available since Python 2.3 was released in 2003. This is a big win in terms of readability and performance\n",
    "\n",
    "Other reducing built-ins are all and any: \n",
    "\n",
    "all(iterable)\n",
    "return True if every element of the iterable is truthy;all([]) returns True. \n",
    "\n",
    "any(iterable)\n",
    "return True if any element of the iterable is truthy;all([]) returns False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6, 120]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(fact, range(6))) # with map\n",
    "[fact(n) for n in range(6)] # with list comp\n",
    "\n",
    "list(map(factorial, filter(lambda n: n % 2, range(6)))) # map filter\n",
    "[factorial(n) for n in range(6) if n % 2] # map filter with list compre\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anonymous functions\n",
    "\n",
    "The lambda keyword creates an anonymous function within a Python expression.\n",
    "However, the simple syntax of Python limits the body of lambda functions to be pure expressions. In other words, the body of a lambda cannot make assignments or use any other Python statement such as while, try etc.\n",
    "The best use of anonymous functions is in the context of an argument list. For example, here is the rhyme index example from Example 5-4 rewritten with lambda, without defining a reverse function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['banana', 'apple', 'fig', 'raspberry', 'strawberry', 'cherry']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana']\n",
    "sorted(fruits, key=lambda word: word[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lundh’s lambda refactoring recipe\n",
    "If you find a piece of code hard to understand because of a lambda, Fredrik Lundh\n",
    "suggests this refactoring procedure:\n",
    "1. Write a comment explaining what the heck that lambda does.\n",
    "2. Study the comment for a while, and think of a name that captures the essence of the comment.\n",
    "3. Convert the lambda to a def statement, using that name.\n",
    "4. Remove the comment.\n",
    "\n",
    "\n",
    "**The lambda syntax is just syntactic sugar: a lambda expression creates a function object just like the def statement. That is just one of several kinds of callable objects in Python.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The seven flavors of callable objects\n",
    "The call operator, i.e. (), may be applied to other objects beyond user-defined functions. To determine whether an object is callable, use the callable() built-in function. The Python Data Model documentation lists seven callable types:\n",
    "### User-defined functions\n",
    "created with def statements or lambda expressions. \n",
    "### Built-in functions\n",
    "a function implemented in C (for CPython), like len or time.strftime. \n",
    "### Built-in methods\n",
    "methods implemented in C, like dict.get.\n",
    "### Methods\n",
    "functions defined in the body of a class.\n",
    "### Classes\n",
    "when invoked, a class runs its __new__ method to create an instance, then __in it__ to initialize it, and finally the instance is returned to the caller. Because there is no new operator in Python, calling a class is like calling a function2.\n",
    "### Class instances\n",
    "if a class defines a __call__ method, then its instances may be invoked as functions. See “User defined callable types” on page 145 below.\n",
    "### Generator functions\n",
    "functions or methods that use the yield keyword. When called, generator functions return a generator object.\n",
    "\n",
    "Given the variety of existing callable types in Python, the safest way to determine whether an object is callable is to use the callable() built-in:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs, str, 13\n",
    "[callable(obj) for obj in (abs, str, 13)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined callable types\n",
    "Not only are Python functions real objects, but arbitrary Python objects may also be made to behave like functions. Implementing a \"\\__call__\" instance method is all it takes.\n",
    "Example below implements a BingoCage class. An instance is built from any iterable, and stores an internal list of items, in random order. Calling the instance pops an item.\n",
    "\n",
    "A class implementing \\__call__ is an easy way to create function-like objects that have some internal state that must be kept across invocations, like the remaining items in the BingoCage. An example is a decorator. Decorators must be functions, but it is sometimes convenient to be able to “remember” something between calls of the decorator, for example for memoization — caching the results of expensive computations for later use.\n",
    "A totally different approach to creating functions with internal state is to use closures. Closures, as well as decorators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "8\n",
      "2\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "class BingoCage:\n",
    "    def __init__(self, items): \n",
    "        self._items = list(items) \n",
    "        random.shuffle(self._items)\n",
    "    def pick(self): \n",
    "        try:\n",
    "            return self._items.pop() \n",
    "        except IndexError:\n",
    "            raise LookupError('pick from empty BingoCage') \n",
    "    def __call__(self):\n",
    "        return self.pick()\n",
    "    \n",
    "bingo = BingoCage(range(10))\n",
    "print(bingo.pick())\n",
    "print(bingo())\n",
    "print(bingo())\n",
    "print(callable(bingo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function introspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Function objects have many attributes beyond \\__doc__. See below what the dir function reveals about our factorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__closure__',\n",
       " '__code__',\n",
       " '__defaults__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__globals__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__kwdefaults__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(factorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### -----------------\n",
    "Most of these attributes are common to Python objects in general. In this section we cover those which are especially relevant to treating functions as objects, starting with \\__dict__.\n",
    "Like the instances of a plain user-defined class, a function uses the \\__dict__ attribute to store user attributes assigned to it. This is useful as a primitive form of annotation. Assigning arbitrary attributes to functions is not a very common practice in general, but Django is one framework that uses it. See, for example, the short_description, boolean and allow_tags attributes described in The Django admin site documentation. In the Django docs this example shows attaching a short_description to a method, to determine the description that will appear in record listings in the Django admin when that method is used:\n",
    "\n",
    "```def upper_case_name(obj):\n",
    "    return (\"%s %s\" % (obj.first_name, obj.last_name)).upper()\n",
    "upper_case_name.short_description = 'Customer name'\n",
    "```\n",
    "\n",
    "Now let us focus on the attributes that are specific to functions and are not found in a generic Python user-defined object. Computing the difference of two sets quickly gives us a list of the function-specific attributes:\n",
    "\n",
    "#### Listing attributes of functions that don’t exist in plain instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__call__',\n",
       " '__closure__',\n",
       " '__code__',\n",
       " '__defaults__',\n",
       " '__get__',\n",
       " '__globals__',\n",
       " '__kwdefaults__',\n",
       " '__name__',\n",
       " '__qualname__']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class C: pass\n",
    "obj=C()\n",
    "def func(): pass\n",
    "sorted(set(dir(func)) - set(dir(obj)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From positional to keyword-only parameters\n",
    "One of the best features of Python functions is the extremely flexible parameter handling mechanism, enhanced with keyword-only arguments in Python 3. Closely related are the use of \\* and \\** to “explode” iterables and mappings into separate arguments when we call a function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>hello</p>\n",
      "<p>world</p>\n",
      "<p class=\"sidebar\">hello</p>\n",
      "<p class=\"sidebar\">world</p>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<img class=\"framed\" src=\"sunset.jpg\" title=\"Sunset Boulevard\" />'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tag(name, *content, cls=None, **attrs): \n",
    "    \"\"\"Generate one or more HTML tags\"\"\"\n",
    "    if cls is not None:\n",
    "        attrs['class'] = cls \n",
    "    if attrs:\n",
    "        attr_str = ''.join(' {}=\"{}\"'.format(attr, value) for attr, value in sorted(attrs.items()))\n",
    "    else:\n",
    "        attr_str = ''\n",
    "    if content:\n",
    "        return '\\n'.join('<{}{}>{}</{}>'.format(name, attr_str, c, name) for c in content) \n",
    "    else:\n",
    "        return '<{}{} />'.format(name, attr_str)\n",
    "\n",
    "#A single positional argument produces an empty tag with that name.\n",
    "tag('br')\n",
    "#Any number of arguments after the first are captured by *content as a tuple.\n",
    "tag('p', 'hello')\n",
    "print(tag('p', 'hello', 'world'))\n",
    "#Keyword arguments not explicitly named in the tag signature are captured by **attrs as a dict.\n",
    "tag('p', 'hello', id=33)\n",
    "# The cls parameter can only be passed as a keyword argument.\n",
    "print(tag('p', 'hello', 'world', cls='sidebar'))\n",
    "# Even the first positional argument can be passed as a keyword when tag is called.\n",
    "tag(content='testing', name=\"img\")\n",
    "# Prefixing the my_tag dict with ** passes all its items as separate arguments which are then bound to the named parameters,\n",
    "# with the remaining caught by **attrs.\n",
    "my_tag = {'name': 'img', 'title': 'Sunset Boulevard', 'src': 'sunset.jpg', 'cls': 'framed'}\n",
    "tag(**my_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : Keyword-only arguments are a new feature in Python 3. In Example above the cls parameter can only be given as a keyword argument — it will never capture unnamed positional arguments. To specify keyword-only arguments when defining a function, name them after the argument prefixed with \\*. If you don’t want to support variable\n",
    "￼￼￼￼￼￼￼￼￼￼￼￼￼From positional to keyword-only parameters\n",
    "positional arguments but still want keyword-only arguments, put a \\* by itself in the signature, like this:\n",
    "\n",
    "```\n",
    "def f(a, *, b):\n",
    "    return a, b \n",
    "    \n",
    ">>> f(1, b=2)\n",
    "(1, 2)\n",
    "\n",
    "```\n",
    "\n",
    "Note that keyword-only arguments do not need to have a default value: they can be\n",
    "mandatory, like b in the example above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving information about parameters\n",
    "\n",
    "```\n",
    "### hello.py\n",
    "import bobo\n",
    "@bobo.query('/') \n",
    "def hello(person):\n",
    "    return 'Hello %s!' % person\n",
    "    \n",
    "bobo -f hello.py\n",
    "\n",
    "```\n",
    "If you install Bobo and point its development server to the code above (e.g. bobo -f hello.py), a hit on the URL http://localhost:8080/ will produce the message “Miss‐ ing form variable person” with a 403 HTTP code. This happens because Bobo under‐ stands that the person argument is required to call hello, but no such name was found in the request.\n",
    "\n",
    "\n",
    "However if you get http://localhost:8080/?person=Jim, the response will be the string 'Hello Jim!'\n",
    "\n",
    "How does Bobo know what are the parameter names required by the function, and whether they have default values or not?\n",
    "Within a function object, the \\__defaults__ attribute holds a tuple with the default values of positional and keyword arguments. The defaults for keyword-only arguments appear in \\__kwdefaults__. The names of the arguments, however, are found within the \\__code__ attribute, which is a reference to a code object with many attributes of its own.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clip(text, max_len=80):\n",
    "    \"\"\"Return text clipped at the last space before or after max_len \"\"\"\n",
    "    end = None\n",
    "    if len(text) > max_len:\n",
    "        space_before = text.rfind(' ', 0, max_len) \n",
    "        if space_before >= 0:\n",
    "            end = space_before \n",
    "        else:\n",
    "            space_after = text.rfind(' ', max_len) \n",
    "            if space_after >= 0:\n",
    "                end = space_after\n",
    "    if end is None: # no spaces were found\n",
    "        end = len(text)\n",
    "    return text[:end].rstrip()\n",
    "\n",
    "\n",
    "clip.__defaults__\n",
    "clip.__code__\n",
    "clip.__code__.co_varnames\n",
    "clip.__code__.co_argcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is not the most convenient arrangement of information. The argument names appear in \\__code__.co_varnames, but that also includes the names of the local variables created in the body of the function. Therefore the argument names are the first N strings, where N is given by \\__code__.co_argcount which — by the way — does not include any variable arguments prefixed with \\* or \\*\\*. The default values are identified only by their position in the __defaults__ tuple, so to link each with the respective argument you have to scan from last to first. In the example, we have two arguments, text and max_len, and one default, 80, so it must belong to the last argument, max_len. This is awkward.\n",
    "Fortunately there is a better way: \n",
    "the **inspect** module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIONAL_OR_KEYWORD : text = <class 'inspect._empty'>\n",
      "POSITIONAL_OR_KEYWORD : max_len = 80\n"
     ]
    }
   ],
   "source": [
    "from inspect import signature\n",
    "sig = signature(clip)\n",
    "for name, param in sig.parameters.items():\n",
    "    print(param.kind, ':', name, '=', param.default)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better: inspect.signature returns an inspect.Signature object, which has a parameters attribute that lets you read an ordered mapping of names to inspect.Pa rameter objects. Each Parameter instance has attributes such as name, default and kind. The special value inspect._empty denotes parameters with no default — which makes sense considering that None is a valid — and popular — default value.\n",
    "\n",
    "The kind attribute holds one of five possible values from _ParameterKind class:\n",
    "POSITIONAL_OR_KEYWORD\n",
    "a parameter that may be passed as a positional or as a keyword argument (most Python function parameters are of this kind).\n",
    "VAR_POSITIONAL\n",
    "a tuple of positional parameters.\n",
    "VAR_KEYWORD\n",
    "a dict of keyword parameters.\n",
    "KEYWORD_ONLY\n",
    "a keyword-only parameter (new in Python 3).\n",
    "POSITIONAL_ONLY a positional-only parameter;\n",
    "\n",
    "currently unsupported by Python function declaration syntax, but exemplified by existing functions implemented in C — like divmod — that do not accept parameters passed by keyword.\n",
    "Besides name, default and kind, inspect.Parameter objects have an annotation at‐ tribute which is usually inspect._empty but may contain function signature metadata provided via the new annotations syntax in Python 3 (annotations are covered in the next section).\n",
    "\n",
    "An inspect.Signature object has a bind method that takes any number of arguments and binds them to the parameters in the signature, applying the usual rules for matching actual arguments to formal parameters. This can be used by a framework to validate arguments prior to the actual function invocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function annotations\n",
    "Python 3 provides syntax to attach metadata to the parameters of a function declaration and its return value. Example 5-19 is an annotated version of Example 5-15. The only differences are in the first line.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_len': 'int > 0', 'return': str, 'text': str}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clip_annon(text:str, max_len:'int > 0'=80) -> str:\n",
    "    \"\"\"Return text clipped at the last space before or after max_len \"\"\"\n",
    "    end = None\n",
    "    if len(text) > max_len:\n",
    "        space_before = text.rfind(' ', 0, max_len) \n",
    "        if space_before >= 0:\n",
    "            end = space_before \n",
    "        else:\n",
    "            space_after = text.rfind(' ', max_len) \n",
    "        if space_after >= 0:\n",
    "            end = space_after\n",
    "    if end is None: # no spaces were found\n",
    "        end = len(text)\n",
    "    return text[:end].rstrip()\n",
    "clip_annon.__annotations__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each argument in the function declaration may have an annotation expression preceded by :. If there is a default value, the annotation goes between the argument name and the = sign. To annotate the return value, add -> and another expression between the ) and the : at the tail of the function declaration. The expressions may be of any type. The most common types used in annotations are classes, like str or int, or strings, like 'int > 0', as seen in the annotation for max_len in Example 5-19.\n",
    "\n",
    "No processing is done with the annotations. They are merely stored in the __annotations__ attribute of the function, a dict:\n",
    "```\n",
    ">>> from clip_annot import clip\n",
    ">>> clip.__annotations__\n",
    "{'text': <class 'str'>, 'max_len': 'int > 0', 'return': <class 'str'>}\n",
    "\n",
    "```\n",
    "The item with key 'return' holds the return value annotation marked with -> in the function declaration in Example 5-19.\n",
    "\n",
    "The only thing Python does with annotations is to store them in the __annotations__ attribute of the function. Nothing else: no checks, enforcement, validation, or any other action is performed. In other words, annotations have no meaning to the Python interpreter. They are just metadata that may be used by tools, such as IDEs, frameworks and decorators. At this writing no tools that use this metadata exist in the standard library, except that inspect.signature() knows how to extract the annota‐ tions, as Example 5-20 shows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages for functional programming\n",
    "\n",
    "Although Guido makes it clear that Python does not aim to be a functional program‐ ming language, a functional coding style can be used to good extent, thanks to the support of packages like operator and functools, which we cover in the next two sections.\n",
    "### The operator module\n",
    "Often in functional programming it is convenient to use an arithmetic operator as a function. For example, suppose you want to multiply a sequence of numbers to calculate factorials without using recursion. To perform summation you can use sum, but there is no equivalent function for multiplication. You could use reduce — as we saw in “Modern replacements for map, filter and reduce” on page 142 — but this requires a function to multiply two items of the sequence. Here is how to solve this using lambda:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "def fact(n):\n",
    "    return reduce(lambda a, b: a*b, range(1, n+1))\n",
    "fact(4)\n",
    "\n",
    "# To save you the trouble of writing trivial anonymous functions like lambda a, b: a*b, \n",
    "# the operator module provides function equivalents for dozens of arithmetic operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from operator import mul \n",
    "def fact(n):\n",
    "    return reduce(mul, range(1, n+1))\n",
    "\n",
    "# Another group of one-trick lambdas that operator replaces are functions to pick items from sequences\n",
    "# or read attributes from objects: itemgetter and attrgetter actually build custom functions to do that.\n",
    "\n",
    "fact(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### methodcaller\n",
    "Of the remaining operator functions, methodcaller is the last we will cover. It is some‐ what similar to attrgetter and itemgetter in that it creates a function on-the-fly. The function it creates calls a method by name on the object given as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The-time-has-come'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import methodcaller \n",
    "s = 'The time has come'\n",
    "upcase = methodcaller('upper') \n",
    "upcase(s)\n",
    "hiphenate = methodcaller('replace', ' ', '-') \n",
    "hiphenate(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first test in Example 5-25 is there just to show methodcaller at work, but if you need to use the str.upper as a function you can just call it on the str class and pass a string as argument, like this:\n",
    "```\n",
    ">>> str.upper(s) \n",
    "'THE TIME HAS COME'\n",
    "```\n",
    "The second test in Example 5-25 shows that methodcaller can also do a partial appli‐ cation to freeze some arguments, like the functools.partial function does. That is our next subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing arguments with functools.partial\n",
    "\n",
    "The functools module brings together a handful of higher-order functions. The best known of them is probably reduce, which was covered in “Modern replacements for map, filter and reduce” on page 142. Of the remaining functions in functools the most useful is partial and its variation, partialmethod.\n",
    "\n",
    "The functools.partial is a higher-order function that allows partial application of a function. Given a function, a partial application produces a new callable with some of the arguments of the original function fixed. This is useful to adapt a function that takes one or more arguments to an API that requires a callback with less arguments. Example 5-26 is a trivial demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 9, 12, 15, 18, 21, 24, 27]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using partial to use a 2-argument function where a 1-argument calla‐ ble is required.\n",
    "from operator import mul\n",
    "from functools import partial \n",
    "triple = partial(mul, 3)\n",
    "triple(7)\n",
    "\n",
    "list(map(triple, range(1, 10))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functiona summary\n",
    "\n",
    "The goal of this chapter was to explore the first-class nature of functions in Python. The main ideas are that you can assign functions to variables, pass them to other functions, store them in data structures and access function attributes, allowing frameworks and tools to act on that information. Higher-order functions, a staple of functional pro‐ gramming, are common in Python — even if the use of map, filter and reduce is not as frequent as it was — thanks to list comprehensions (and similar constructs like gen‐ erator expressions) and the appearance of reducing built-ins like sum, all and any. The sorted, min, max built-ins, and functools.partial are examples of commonly used higher-order functions in the language.\n",
    "\n",
    "Callables come in seven different flavors in Python, from the simple functions created with lambda to instances of classes implementing __call__. They can all be detected by the callable() built-in. Every callable supports the same rich syntax for declaring formal parameters, including keyword-only parameters and annotations — both new features introduced with Python 3.\n",
    "\n",
    "Python functions and their annotations have a rich set of attributes that can be read with the help of the inspect module, which includes the Signature.bind method to apply the flexible rules that Python uses to bind actual arguments to declared parameters.\n",
    "\n",
    "Lastly, we covered some functions from the operator module and functools.parti al, which facilitate functional programming by minimizing the need for the functionally-challenged lambda syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function decorators and closures\n",
    "\n",
    "Function decorators let us “mark” functions in the source code to enhance their behavior is some way. This is powerful stuff, but mastering it requires understanding closures.\n",
    "\n",
    "One of the newest reserved keywords in Python is nonlocal, introduced in Python 3.0. You can have a profitable life as a Python programmer without ever using it if you adhere to a strict regimen of class-centered object orientation. However, if you want to imple‐ ment your own function decorators, you must know closures inside out, and then the need for nonlocal becomes obvious.\n",
    "\n",
    "Aside from their application in decorators, closures are also essential for effective asyn‐ chronous programming with callbacks, and for coding in a functional style whenever it makes sense.\n",
    "The end goal of this chapter is to explain exactly how function decorators work, from the simplest registration decorators to the rather more complicated parametrized ones. However, before we reach that goal we need to cover\n",
    "\n",
    "\n",
    "### Decorators 101\n",
    "\n",
    "A decorator is a callable that takes another function as argument (the decorated func‐ tion). The decorator may perform some processing with the decorated function, and returns it or replaces it with another function or callable object.\n",
    "In other words, this code:\n",
    "```\n",
    "@decorate\n",
    "def target():\n",
    "    print('running target()')\n",
    "```\n",
    "Has the same effect as writing this:\n",
    "\n",
    "```\n",
    "def target():\n",
    "    print('running target()')\n",
    "\n",
    "target = decorate(target)\n",
    "```\n",
    "\n",
    "** The end result is the same: \n",
    "at the end of either of these snippets, the target name does not necessarily refer to the original target function, but to whatever function is re‐ turned by decorate(target). **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running inner()\n"
     ]
    }
   ],
   "source": [
    "def deco(func):\n",
    "    def inner():\n",
    "        print('running inner()')\n",
    "    return inner\n",
    "\n",
    "@deco\n",
    "def target():\n",
    "    print('running target()')\n",
    "target()\n",
    "\n",
    "# deco returns its inner function object.\n",
    "# target is decorated by deco.\n",
    "# Invoking the decorated target actually runs inner. \n",
    "# Inspection reveals that target is a now a reference to inner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Strictly speaking, decorators are just syntactic sugar. As we just saw, you can always simply call a decorator like any regular callable, passing another function. Sometimes that is actually convenient, especially when doing metaprogramming — changing program behavior at run-time.\n",
    "\n",
    "**To summarize: the first crucial fact about decorators is that they have the power to replace the decorated function with a different one. The second crucial fact is that they are executed immediately when a module is loaded. This is explained next. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When Python executes decorators\n",
    "\n",
    "A key feature of decorators is that they run right after the decorated function is defined. That is usually at import time, i.e. when a module is loaded by Python. Consider registration.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running register(<function f1 at 0x1052886a8>)\n",
      "running register(<function f2 at 0x1052887b8>)\n",
      "running main()\n",
      "registry -> [<function f1 at 0x1052886a8>, <function f2 at 0x1052887b8>]\n",
      "running f1()\n",
      "running f2()\n",
      "running f3()\n"
     ]
    }
   ],
   "source": [
    "registry = []\n",
    "def register(func):\n",
    "\tprint('running register(%s)' % func) \n",
    "\tregistry.append(func)\n",
    "\treturn func\n",
    "\n",
    "@register\n",
    "def f1():\n",
    "\tprint('running f1()')\n",
    "\n",
    "@register\n",
    "def f2():\n",
    "\tprint('running f2()')\n",
    "\n",
    "def f3():\n",
    "\tprint('running f3()')\n",
    "\n",
    "def main():\n",
    "\tprint('running main()') \n",
    "\tprint('registry ->', registry) \n",
    "\tf1()\n",
    "\tf2()\n",
    "\tf3()\n",
    "if __name__== '__main__':\n",
    "\tmain()\n",
    "\n",
    "# output:\n",
    "# 1. \n",
    "# >>> import registration\n",
    "# running register(<function f1 at 0x10192d400>)\n",
    "# running register(<function f2 at 0x10192d488>)\n",
    "\n",
    "# 2. python registration.py\n",
    "# running register(<function f1 at 0x1018d8ea0>)\n",
    "# running register(<function f2 at 0x1018d8f28>)\n",
    "# running main()\n",
    "# registry -> [<function f1 at 0x1018d8ea0>, <function f2 at 0x1018d8f28>]\n",
    "# running f1()\n",
    "# running f2()\n",
    "# running f3()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main point of above example\n",
    "is to emphasize that function decorators are executed as soon as the module is imported, but the decorated functions only run when they are explicitly invoked. This highlights the difference between what Pythonistas call **import time** and **run time**.\n",
    "\n",
    "Considering how decorators are commonly employed in real code, Example 7-2 is un‐ usual in two ways:\n",
    "\n",
    "• The decorator function is defined in the same module as the decorated functions. A real decorator is usually defined in one module and applied to functions in other modules.\n",
    "• Theregisterdecoratorreturnsthesamefunctionpassedasargument.Inpractice, most decorators define an inner function and return it.\n",
    "\n",
    "Even though the register decorator in Example 7-2 returns the decorated function unchanged, that technique is not useless. Similar decorators are used in many Python Web frameworks to add functions to some central registry, for example, a registry map‐ ping URL patterns to functions that generate HTTP responses. Such registration dec‐ orators may or may not change the decorated function. The next section shows a prac‐ tical example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<function fidelity at 0x105288ea0>, <function bulk_item at 0x105288e18>, <function large_order at 0x105288d90>]\n"
     ]
    }
   ],
   "source": [
    "### Decorator-enhanced Strategy pattern\n",
    "\n",
    "promos = []\n",
    "def promotion(promo_func):\n",
    "\tpromos.append(promo_func) \n",
    "\treturn promo_func\n",
    "\n",
    "@promotion\n",
    "def fidelity(order):\n",
    "\t\"\"\"5% discount for customers with 1000 or more fidelity points\"\"\" \n",
    "\treturn order.total() * .05 if order.customer.fidelity >= 1000 else 0\n",
    "\n",
    "@promotion\n",
    "def bulk_item(order):\n",
    "\t\"\"\"10% discount for each LineItem with 20 or more units\"\"\" \n",
    "\tdiscount = 0\n",
    "\tfor item in order.cart:\n",
    "\t\tif item.quantity >= 20:\n",
    "\t\t\tdiscount += item.total() * .1\n",
    "\treturn discount\n",
    "\n",
    "@promotion\n",
    "def large_order(order):\n",
    "\t\"\"\"7% discount for orders with 10 or more distinct items\"\"\" \n",
    "\tdistinct_items = {item.product for item in order.cart}\n",
    "\tif len(distinct_items) >= 10:\n",
    "\t\treturn order.total() * .07 \n",
    "\treturn 0\n",
    "\n",
    "def best_promo(order):\n",
    "\t\"\"\"Select best discount available\"\"\"\n",
    "\treturn max(promo(order) for promo in promos)\n",
    "\n",
    "print(promos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most decorators do change the decorated function. They usually do it by defining an inner function and returning it to replace the decorated function. Code that uses inner functions almost always depends on closures to operate correctly. To understand clo‐ sures, we need to take a step back a have a close look at how variable scopes work in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Variable scope rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "10\n",
      "2000\n",
      "100\n",
      "2000\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'c' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-1894d78c2be8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mf12\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-1894d78c2be8>\u001b[0m in \u001b[0;36mf12\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf12\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'c' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# b is not local to function f1..if not found it will look for global b=10\n",
    "def f1(a):\n",
    "    print(a)\n",
    "    print(b)\n",
    "  \n",
    "b=10\n",
    "f1(20)\n",
    "\n",
    "# though b=10 is global we can still redefine b=100 which overrides global\n",
    "def f1(a):\n",
    "    print(a)\n",
    "    b=100\n",
    "    print(b)\n",
    "f1(2000)\n",
    "\n",
    "# though c is global we can still redefine c=100 ,python when it creates function objects it \n",
    "#  it marks as local variable hence it will complain when it si accessed before assignment.\n",
    "def f12(a):\n",
    "    print(a)\n",
    "    print(c)\n",
    "    c=100\n",
    "c=12\n",
    "f12(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output starts with 3, which proves that the print(a) statement was exe‐ cuted. But the second one, print(b) never runs. When I first saw this I was surprised, thinking that 6 should be printed, because there is a global variable b and the assignment to the local b is made after print(b).\n",
    "\n",
    "But the fact is, when Python compiles the body of the function, it decides that b is a local variable because it is assigned within the function. The generated bytecode reflects this decision and will try to fetch b from the local environment. Later, when the call f2(3) is made, the body of f2 fetches and prints the value of the local variable a, but when trying to fetch the value of local variable b it discovers that b is unbound.\n",
    "\n",
    "This is not a bug, but a design choice: Python does not require you to declare variables, but assumes that a variable assigned in the body of a function is local. This is much better than the behavior of JavaScript, which does not require variable declarations either, but if you do forget to declare that a variable is local (with var), you may clobber a global variable without knowing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making chnages to global variable\n",
    "\n",
    "If we want the interpreter to treat b as a global variable in spite of the assignment within the function, we use the global declaration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "121\n",
      "10\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "bb = 100\n",
    "def f3(a):\n",
    "    global bb\n",
    "    print(a)\n",
    "    print(b)\n",
    "    bb=999\n",
    "print(bb) # global values\n",
    "f3(121)\n",
    "print(bb) # locally chnaged global variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closures\n",
    "\n",
    "In the blogosphere closures are sometimes confused with anonymous functions. The reason why many confuse them is historic: defining functions inside functions is not so common, until you start using anonymous functions. And closures only matter when you have nested functions. So a lot of people learn both concepts at the same time.\n",
    "\n",
    "** Actually, a closure is function with an extended scope that encompasses non-global variables referenced in the body of the function but not defined there. It does not matter whether the function is anonymous or not, what matters is that it can access non-global variables that are defined outside of its body. **\n",
    "\n",
    "This is a challenging concept to grasp, and is better approached through an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Averager():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.series = []  ## lo\n",
    "        \n",
    "    def __call__(self, new_value):\n",
    "        self.series.append(new_value)\n",
    "        total = sum(self.series)\n",
    "        return total/len(self.series)\n",
    "        \n",
    "avg = Averager()\n",
    "avg(10)\n",
    "avg(12)\n",
    "avg(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is a functional implementation, using a higher order function make_averager:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_averager():\n",
    "    series = []  # --> closure\n",
    "    \n",
    "    def averager(new_value):\n",
    "        series.append(new_value)  # --> free vraiable\n",
    "        total = sum(series) \n",
    "        return total/len(series)\n",
    "    \n",
    "    return averager\n",
    "\n",
    "# When invoked, make_averager returns an averager function object. Each time an averager is called,\n",
    "# it appends the passed argument to the series, and computes the current average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = make_averager()\n",
    "avg(10)\n",
    "avg(12)\n",
    "avg(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the similarities of the examples: we call Averager() or make_averager() to get a callable object avg that will update the historical series and calculate the current mean. In Example 7-8, avg is an instance of Averager, and in Example 7-9 it is the inner function, averager. Either way, we just call avg(n) to include n in the series and get the updated mean.\n",
    "\n",
    "It’s obvious where the avg of the Averager class keeps the history: the self.series instance attribute. But where does the avg function in the second example find the series?\n",
    "Note that series is a local variable of make_averager because the initialization series = [] happens in the body of that function. But when avg(10) is called, make_averag er has already returned, its local scope is long gone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "￼Within averager, series is a free variable. This is a technical term meaning a variable that is not bound in the local scope. See Figure 7-1.\n",
    "Inspecting the returned averager object shows how Python keeps the names of local and free variables in the __code__ attribute that represents the compiled body of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('new_value', 'total')\n",
      "1\n",
      "('series',)\n"
     ]
    }
   ],
   "source": [
    "print(avg.__code__.co_varnames)\n",
    "print(avg.__code__.co_argcount)\n",
    "print(avg.__code__.co_freevars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binding for series is kept in the \\__closure\\__ attribute of the returned function avg. Each item in avg.\\__closure\\__ corresponds to a name in avg.\\__code\\__.co_free vars. These items are cells, and they have an attribute cell_contents where the actual value can be found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('series',)\n",
      "(<cell at 0x104cfcd68: list object at 0x10528a408>,)\n",
      "[10, 12, 20]\n"
     ]
    }
   ],
   "source": [
    "print(avg.__code__.co_freevars)\n",
    "print(avg.__closure__)\n",
    "print(avg.__closure__[0].cell_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To summarize: a closure is function that retains the bindings of the free variables that exist when the function is defined, so that they can be used later when the function is invoked and the defining scope is no longer available.\n",
    "Note that the only situation in which a function may need to deal with external variables that are non-global is when it is nested in another function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'count' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-c85c5e483073>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_averager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-93-c85c5e483073>\u001b[0m in \u001b[0;36maverager\u001b[0;34m(new_value)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maverager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'count' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def make_averager(): \n",
    "    count = 0\n",
    "    total = 0\n",
    "    def averager(new_value): \n",
    "        count += 1\n",
    "        total += new_value \n",
    "        return total / count\n",
    "    return averager\n",
    "\n",
    "avg = make_averager()\n",
    "avg(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that the statement count += 1 actually means the same as count = count + 1, when count is a number or any immutable type. So we are actually assigning to count in the body of averager, and that makes it a local variable. The same problem affects the total variable.\n",
    "\n",
    "We did not have this problem in Example 7-9 because we never assigned to the ser ies list, we only called series.append and invoked sum and len on it. So we took advantage of the fact that lists are mutable.\n",
    "\n",
    "But with immutable types like numbers, strings, tuples etc., all you can is read, but never update. If you try to rebind them, as in count = count + 1, then you are implicitly creating a local variable count. It is no longer a free variable, therefore it is not saved in the closure.\n",
    "\n",
    "To work around this the nonlocal declaration was introduced in Python 3. It lets you flag a variable as a free variable even when it is assigned a new value within the function. If a new value is assigned to a nonlocal variable, the binding stored in the closure is changed. A correct implementation of our newest make_averager looks like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_averager(): \n",
    "    count = 0\n",
    "    total = 0\n",
    "    def averager(new_value): \n",
    "        nonlocal count, total\n",
    "        count += 1\n",
    "        total += new_value \n",
    "        return total / count\n",
    "    return averager\n",
    "avg = make_averager()\n",
    "avg(12)\n",
    "avg(1288)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a simple decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello........ Mahesh\n",
      "[0.00010930s] custom_print('Hello', 'Mahesh') -> True\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def clock(func):\n",
    "    def clocked(*args): #\n",
    "        t0 = time.perf_counter()\n",
    "        result = func(*args) #\n",
    "        elapsed = time.perf_counter() - t0\n",
    "        name = func.__name__\n",
    "        arg_str = ', '.join(repr(arg) for arg in args)\n",
    "        print('[%0.8fs] %s(%s) -> %r' % (elapsed, name, arg_str, result)) \n",
    "        return result\n",
    "    return clocked\n",
    "\n",
    "@clock\n",
    "def snooze(seconds): \n",
    "    time.sleep(seconds)\n",
    "\n",
    "@clock\n",
    "def factorial(n):\n",
    "    return 1 if n < 2 else n*factorial(n-1)\n",
    "\n",
    "@clock\n",
    "def custom_print(saltn, name):\n",
    "    print(\"{}........ {}\".format(saltn, name))\n",
    "    return True\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # print('*' * 40, 'Calling snooze(.123)') \n",
    "    # snooze(.123)\n",
    "    # print('*' * 40, 'Calling factorial(6)') \n",
    "    # print('6! =', factorial(6))\n",
    "    custom_print(\"Hello\", \"Mahesh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clocked'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_print.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the typical behavior of a decorator: it replaces the decorated function with a new function that accepts the same arguments and (usually) returns whatever the decorated function was supposed to return, while also doing some extra processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clock decorator implemented in above has a few shortcomings: it does not support keyword arguments, and it masks the __name__ and __doc__ of the decorated function. Example below uses the functools.wraps decorator to copy the relevant at‐ tributes from func to clocked. Also, in this new version keyword arguments are correctly handled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello........ Mahesh\n",
      "[0.00003695s] custom_print('Hello', 'Mahesh') -> True \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import functools\n",
    "\n",
    "def clock(func):\n",
    "    @functools.wraps(func)\n",
    "    def clocked(*args, **kwargs):\n",
    "        t0 = time.time()\n",
    "        result = func(*args, **kwargs) \n",
    "        elapsed = time.time() - t0 \n",
    "        name = func.__name__\n",
    "        arg_lst = []\n",
    "        if args:\n",
    "            arg_lst.append(', '.join(repr(arg) for arg in args)) \n",
    "        if kwargs:\n",
    "            pairs = ['%s=%r' % (k, w) for k, w in sorted(kwargs.items())]\n",
    "            arg_lst.append(', '.join(pairs))\n",
    "        arg_str = ', '.join(arg_lst)\n",
    "        print('[%0.8fs] %s(%s) -> %r ' % (elapsed, name, arg_str, result)) \n",
    "        return result\n",
    "    return clocked\n",
    "\n",
    "@clock\n",
    "def snooze(seconds): \n",
    "    time.sleep(seconds)\n",
    "\n",
    "@clock\n",
    "def factorial(n):\n",
    "    return 1 if n < 2 else n*factorial(n-1)\n",
    "\n",
    "@clock\n",
    "def custom_print(saltn, name):\n",
    "    print(\"{}........ {}\".format(saltn, name))\n",
    "    return True\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # print('*' * 40, 'Calling snooze(.123)') \n",
    "    # snooze(.123)\n",
    "    # print('*' * 40, 'Calling factorial(6)') \n",
    "    # print('6! =', factorial(6))\n",
    "    custom_print(\"Hello\", \"Mahesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom_print'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_print.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functools.wraps is just one of the ready-to-use decorators in the standard library. In the next section we’ll meet two of the most impressive decorators that functools pro‐ vides: lru_cache and singledispatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memoization with functools.lru_cache\n",
    "A very practical decorator is functools.lru_cache. It implements memoization: an optimization technique which works by saving the results of previous invocations of an expensive function, avoiding repeat computations on previously used arguments. The letters LRU stand for Least Recently Used, meaning that the growth of the cache is limited by discarding the entries that have not been read for a while.\n",
    "\n",
    "A good demonstration is to apply lru_cache to the painfully slow recursive function to generate the Nth number in the Fibonacci sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000095s] fibonacci(0) -> 0 \n",
      "[0.00000095s] fibonacci(1) -> 1 \n",
      "[0.00004196s] fibonacci(2) -> 1 \n",
      "[0.00000000s] fibonacci(1) -> 1 \n",
      "[0.00000000s] fibonacci(0) -> 0 \n",
      "[0.00000095s] fibonacci(1) -> 1 \n",
      "[0.00001907s] fibonacci(2) -> 1 \n",
      "[0.00003695s] fibonacci(3) -> 2 \n",
      "[0.00009799s] fibonacci(4) -> 3 \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "@clock\n",
    "def fibonacci(n): \n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci(n-2) + fibonacci(n-1)\n",
    "if __name__=='__main__': \n",
    "    print(fibonacci(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000095s] fibonacci(0) -> 0 \n",
      "[0.00000095s] fibonacci(1) -> 1 \n",
      "[0.00005198s] fibonacci(2) -> 1 \n",
      "[0.00000095s] fibonacci(3) -> 2 \n",
      "[0.00007510s] fibonacci(4) -> 3 \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "@functools.lru_cache()\n",
    "@clock\n",
    "def fibonacci(n): \n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci(n-2) + fibonacci(n-1)\n",
    "if __name__=='__main__': \n",
    "    print(fibonacci(4))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note :**\n",
    "1. Note that lru_cache must be invoked as a regular function — note the parenthesis in the line: @functools.lru_cache(). The reason is that it accepts configuration parameters, as we’ll see shortly.\n",
    "    \n",
    "2. This is an example of stacked decorators: @lru_cache() is applied on the function returned by @clock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides making silly recursive algorithms viable, lru_cache really shines in applications that need to fetch information from Web.\n",
    "\n",
    "It’s important to note that lru_cache can be tuned by passing two optional arguments. Its full signature is:\n",
    "functools.lru_cache(maxsize=128, typed=False)\n",
    "\n",
    "The maxsize arguments determines how many call results are stored. After the cache is full, older results are discarded to make room. For optimal performance, maxsize should be a power of 2. The typed argument, if set to True, stores results of different argument types separately, i.e. distinguishing between float and integer arguments that are normally considered equal, like 1 and 1.0. By the way, because lru_cache uses a dict to store the results, and the keys are made from the positional and keyword arguments used in the calls, all the arguments taken by the decorated function must be hashable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked decorators\n",
    "Decorators are functions, therefore they may be composed, i.e. you can apply a decorator to a function that is already decorated, as shown in Example 7-21. The next session explains how that works.\n",
    "\n",
    "Example 7-19 demonstrated the use of stacked decorators: @lru_cache is applied on the result of @clock over fibonacci. In Example 7-21 the @htmelize.register deco‐ rator was applied twice to the last function in the module.\n",
    "When two decorators @d1 and @d2 are applied to a function f in that order, the result is the same as f = d1(d2(f)).\n",
    "In other words, this:\n",
    "```\n",
    "@d1\n",
    "@d2\n",
    "def f():\n",
    "    print('f') \n",
    "Is the same as:\n",
    "def f(): \n",
    "    print('f')\n",
    "f = d1(d2(f))\n",
    "```\n",
    "Besides stacked decorators, this chapter has shown some decorators that take argu‐ ments, for example, @lru_cache() and the htmlize.register(«type») produced by @singledispatch in Example 7-21. The next section shows how to build decorators that accept parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametrized Decorators\n",
    "\n",
    "When parsing a decorator in source code, Python takes the decorated function and passes it as the first argument to the decorator function. So how do you make a decorator accept other arguments? The answer is: make a decorator factory that takes those arguments and returns a decorator, which is then applied to the function to be decorated. Confusing? Sure. Let’s start with an example based on the simplest decorator we’ve seen: register in Example 7-22.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running register(<function f1 at 0x1046efea0>)\n",
      "running main()\n",
      "registry -> [<function f1 at 0x1046efea0>]\n",
      "running f1()\n"
     ]
    }
   ],
   "source": [
    "registry = []\n",
    "def register(func):\n",
    "    print('running register(%s)' % func) \n",
    "    registry.append(func)\n",
    "    return func\n",
    "\n",
    "@register\n",
    "def f1():\n",
    "    print('running f1()')\n",
    "\n",
    "print('running main()') \n",
    "print('registry ->', registry) \n",
    "f1()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A parametrized registration decorator\n",
    "In order to make it easy to enable or disable the function registration performed by register, we’ll make it accept an optional active parameter which, if False skips registering the decorated function. Example 7-23 shows how. Conceptually, the new\n",
    "\n",
    "register function is not a decorator but a decorator factory. When called, it returns the actual decorator that will be applied to the target function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running register(active=False)->decorate(<function f1 at 0x10540f0d0>)\n",
      "running register(active=True)->decorate(<function f2 at 0x10540f840>)\n",
      "{<function f2 at 0x10540f840>}\n"
     ]
    }
   ],
   "source": [
    "registry = set()\n",
    "def register(active=True): \n",
    "    def decorate(func):\n",
    "        print('running register(active=%s)->decorate(%s)' % (active, func))\n",
    "        if active: \n",
    "            registry.add(func)\n",
    "        else: \n",
    "            registry.discard(func)\n",
    "        return func \n",
    "    return decorate\n",
    "\n",
    "@register(active=False) \n",
    "def f1():\n",
    "    print('running f1()')\n",
    "    \n",
    "@register() \n",
    "def f2():\n",
    "    print('running f2()') \n",
    "\n",
    "def f3():\n",
    "    print('running f3()')\n",
    "    \n",
    "print(registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables are not boxes\n",
    "In 1997 I took a summer course on Java at MIT. The professor, Lynn Andrea Stein1 — an award-winning computer science educator — made the point that the usual “variables as boxes” metaphor actually hinders the understanding of reference variables in OO languages. Python variables are like reference variables in Java, so it’s better to think of them as labels attached to objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b=a\n",
    "a.append(4)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Python Language Reference — Data model — section 3.1. ** Objects, values and types states:\n",
    "Every object has an identity, a type and a value. An object’s identity never changes once it has been created; you may think of it as the object’s address in memory. The is operator compares the identity of two objects; the id() function returns an integer representing its identity.**\n",
    "\n",
    "The real meaning of an object’s id is implementation-dependent. In CPython, id() returns the memory address of the object, but it may be something else in another Python interpreter. The key point is that the id is guaranteed to be a unique numeric label, and it will never change during the life of the object.\n",
    "\n",
    "In practice, we rarely use the id() function while programming. Identity checks are most often done with the is operator, and not by comparing ids. We’ll talk about is versus == next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing between == and is\n",
    "\n",
    "The == operator compares the values of objects (the data they hold), while is compares\n",
    "their identities.\n",
    "We often care about values and not identities, so == appears more frequently than is in Python code.\n",
    "However, if you are comparing a variable to a singleton, then it makes sense to use is. By far, the most common case is checking whether a variable is bound to None. This is the recommended way to do it:\n",
    "```\n",
    "x is None\n",
    "And the proper way to write its negation is:\n",
    "x is not None\n",
    "```\n",
    "The is operator is faster than ==, because it cannot be overloaded, so Python does not have to find and invoke special methods to evaluate it, and computing is as simple as comparing two integer ids. In contrast, a == b is syntactic sugar for a.\\__eq\\__(b). The \\__eq\\__ method inherited from object compares object ids, so it produces the same result as is. But most built-in types override \\__eq\\__ with more meaningful implemen‐ tations that actually take into account the values of the object attributes. Equality may involve a lot of processing — for example, when comparing large collections or deeply nested structures.\n",
    "To wrap up this discussion of identity versus equality, we’ll see that the famously im‐ mutable tuple is not as rigid as you may expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The relative immutability of tuples\n",
    "\n",
    "Tuples, like most Python collections — lists, dicts, sets etc. — hold references to objects2. If the referenced items are mutable, they may change even if the tuple itself does not. In other words, the immutability of tuples really refers to the physical contents of the tuple data structure (ie. the references it holds), and does not extend to the refer‐ enced objects.\n",
    "\n",
    "illustrates the situation in which the value of a tuple changes as result of changes to a mutable object referenced in it. What can never change in a tuple is the identity of the items it contains.\n",
    "\n",
    "It’s also the reason why some tuples are unhashable, as we’ve seen in “What is hashable?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4375990472\n",
      "4375990472\n",
      "[30, 40, 50]\n"
     ]
    }
   ],
   "source": [
    "t1 = (1, 2, [30, 40])\n",
    "t2 = (1, 2, [30, 40])\n",
    "t1 == t2\n",
    "print(id(t1[-1]))\n",
    "t1[-1].append(50)\n",
    "print(id(t1[-1]))\n",
    "print(t1[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distinction between equality and identity has further implications when you need to copy an object. A copy is an equal object with a different id. But if an object contains other objects, should the copy also duplicate the inner objects, or is it ok to share them? There’s no single answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copies are shallow by default\n",
    "\n",
    "The easiest way to copy a list (or most built-in mutable collections) is to use the built- in constructor for the type itself, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "l1 = [3, [55, 44], (7, 8, 9)]\n",
    "l2 = list(l1)\n",
    "l1[-2].append(33)\n",
    "l3 = l1[:]\n",
    "print(l2 == l1)\n",
    "print(l2 is l1)\n",
    "\n",
    "# http://www.pythontutor.com/visualize.html#code=l1+%3D+%5B3,+%5B55,+44%5D,+(7,+8,+9%29%5D%0Al2+%3D+list(l1%29%0Al1%5B-2%5D.append(33%29%0Al3+%3D+l1%5B%3A%5D%0Aprint(l2+%3D%3D+l1%29%0Aprint(l2+is+l1%29&mode=display&origin=opt-frontend.js&cumulative=false&heapPrimitives=false&textReferences=false&py=2&rawInputLstJSON=%5B%5D&curInstr=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For lists and other mutable sequences, the shortcut l2 = l1[:] also makes a copy.\n",
    "However, using the constructor or [:] produces a shallow copy, i.e. the outermost con‐ tainer is duplicated, but the copy is filled with references to the same items held by the original container. This saves memory and causes no problems if all the items are im‐ mutable. But if there are mutable items, this may lead to unpleasant surprises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep and shallow copies of arbitrary objects\n",
    "\n",
    "It should be clear now that shallow copies are easy to make, but they may or may not be what you want. How to make deep copies is our next topic.\n",
    "\n",
    "Working with shallow copies is not always a problem, but sometimes you need to make deep copies, i.e. duplicates that do not share references of embedded objects. The copy\n",
    "\n",
    "module provides the deepcopy and copy functions that return deep and shallow copies of arbitrary objects.\n",
    "\n",
    "To illustrate the use of copy() and deepcopy(), Example 8-8 defines a simple class Bus, representing a school bus that is loaded with passengers and then picks or drops passengers on its route.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alice', 'Bill', 'Claire', 'David']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Bus:\n",
    "    def __init__(self, passengers=None): \n",
    "        if passengers is None:\n",
    "            self.passengers = [] \n",
    "        else:\n",
    "            self.passengers = list(passengers)\n",
    "    \n",
    "    def pick(self, name):\n",
    "            self.passengers.append(name) \n",
    "    def drop(self, name):\n",
    "            self.passengers.remove(name)\n",
    "            \n",
    "import copy\n",
    "bus1 = Bus(['Alice', 'Bill', 'Claire', 'David'])\n",
    "bus2 = copy.copy(bus1)\n",
    "bus3 = copy.deepcopy(bus1)\n",
    "id(bus1), id(bus2), id(bus3)\n",
    "bus1.drop('Bill')\n",
    "bus2.passengers\n",
    "id(bus1.passengers), id(bus2.passengers), id(bus3.passengers)\n",
    "\n",
    "bus3.passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that making deep copies is not a simple matter in the general case. Objects may have cyclic references which would cause a naïve algorithm to enter an infinite loop. The deepcopy function remembers the objects already copied to handle cyclic references gracefully. \n",
    "\n",
    "Also, a deep copy may be too deep in some cases. For example, objects may refer to external resources or singletons that should not be copied. You may control the behavior of both copy and deepcopy by implementing the \\__copy\\__() and \\__deepcopy\\__() special methods as described in the copy module documentation.\n",
    "The sharing of objects through aliases also explains how parameter passing works in Python, and the problem of using mutable types as parameter defaults. These issues will be covered next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function parameters as references\n",
    "\n",
    "The only mode of parameter passing in Python is call by sharing. That is the same mode used in most OO languages, including Ruby, SmallTalk and Java3. Call by sharing means that each formal parameter of the function gets a copy of each reference in the argu‐ ments. In other words, the parameters inside the function become aliases of the actual arguments.\n",
    "The result of this scheme is that a function ** may change any mutable object passed as a parameter, but it cannot change the identity of those objects, ** i.e. it cannot replace al‐ together an object with another. Example 8-11 shows a simple function using += on one of its parameters. As we pass numbers, lists and tuples to the function, the actual argu‐ ments passed are affected in different ways.\n",
    "\n",
    "A function may change any mutable object it receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "10\n",
      "(10, 20, 30, 40)\n",
      "(10, 20)\n",
      "[1, 2, 3, 4]\n",
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "## Immutable parameters\n",
    "def f(a, b):\n",
    "    a += b # You can change value but its impact is local -> 30\n",
    "    return a\n",
    "x=10\n",
    "y=20\n",
    "print(f(x,y))\n",
    "print(x) # outside of function its value is not chnaged. -->10\n",
    "\n",
    "# tuple\n",
    "t = (10, 20)\n",
    "u = (30, 40)\n",
    "print(f(t,u))\n",
    "print(t)\n",
    "\n",
    "## Mutable parameters\n",
    "\n",
    "a = [1, 2]\n",
    "b = [3, 4]\n",
    "print(f(a,b))\n",
    "print(a)  ## As the parameter a is mutable ..so changes take effect even outsie function scope(global)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutable types as parameter defaults: bad idea\n",
    "\n",
    "Optional parameters with default values are a great feature of Python function defini‐ tions, allowing our APIs to evolve while remaining backward-compatible. However, you should avoid mutable objects as default values for parameters.\n",
    "To illustrate this point, we take the Bus class from Example 8-8 and change its __in it__ method to create HauntedBus. Here we tried to be clever and instead of having a default value of passengers=None we have passengers=[], thus avoiding the if in the previous __init__. This “cleverness” gets us into trouble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bill', 'Charlie']\n",
      "['Carrie']\n",
      "['Carrie']\n",
      "['Carrie', 'Dave']\n",
      "['Bill', 'Charlie']\n"
     ]
    }
   ],
   "source": [
    "class HauntedBus:\n",
    "    \"\"\"A bus model haunted by ghost passengers\"\"\"\n",
    "    def __init__(self, passengers=[]): \n",
    "        self.passengers = passengers\n",
    "    def pick(self, name): \n",
    "        self.passengers.append(name)\n",
    "    def drop(self, name): \n",
    "        self.passengers.remove(name)\n",
    "        \n",
    "bus1 = HauntedBus(['Alice', 'Bill'])\n",
    "# print(bus1.passengers)\n",
    "bus1.pick('Charlie')\n",
    "bus1.drop('Alice')\n",
    "print(bus1.passengers)\n",
    "\n",
    "bus2 = HauntedBus() \n",
    "bus2.pick('Carrie') \n",
    "print(bus2.passengers)  # carrie gets added to default list\n",
    "\n",
    "bus3 = HauntedBus() \n",
    "print(bus3.passengers)\n",
    "bus3.pick('Dave') \n",
    "print(bus2.passengers) # carrie of bus 2 is present in bus3?? odd\n",
    "bus2.passengers is bus3.passengers\n",
    "print(bus1.passengers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that Bus instances that don’t get an initial passenger list end up sharing the same passenger list among themselves.\n",
    "Such bugs may be subtle. As Example 8-13 demonstrates, when a HauntedBus is in‐ stantiated with passengers, it works as expected. Strange things happen only when a HauntedBus starts empty, because then self.passengers becomes an alias for the de‐ fault value of the passengers parameter. The problem is that each default value is eval‐ uated when the function is defined — i.e. usually when the module is loaded — and the default values become attributes of the function object. So if a default value is a mutable object, and you change it, the change will affect every future call of the function.\n",
    "After running the lines in Example 8-13 you can inspect the HauntedBus.__init__ object and see the ghost students haunting its __defaults__ attribute.\n",
    "```\n",
    ">>> dir(HauntedBus.__init__) \n",
    "doctest: +ELLIPSIS ['__annotations__', '__call__', ..., '__defaults__', ...] \n",
    ">>> HauntedBus.__init__.__defaults__\n",
    "(['Carrie', 'Dave'],)\n",
    "Finally, we can verify that bus2.passengers is an alias bound to the first element of the HauntedBus.__init__.__defaults__ attribute:\n",
    ">>> HauntedBus.__init__.__defaults__[0] is bus2.passengers True\n",
    "```\n",
    "**The issue with mutable defaults explains why None is often used as the default value for parameters that may receive mutable values. In Example 8-8, __init__ checks whether the passengers argument is None, and assigns a new empty list to self.passengers. If passengers is not None, the correct implementation assigns a copy of it to self.pas sengers. The following section explains why.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defensive programming with mutable parameters\n",
    "\n",
    "When you are coding a function that receives a mutable parameter you should carefully consider whether the caller expects the argument passed to be changed.\n",
    "\n",
    "For example, if your function receives a dict and needs to modify it while processing it, should this side effect be visible outside of the function or not? Actually it depends on the context. It’s really a matter of aligning the expectation of the coder of the function and that of the caller.\n",
    "\n",
    "The last bus example in this chapter shows how a TwilightBus breaks expectations by sharing its passenger list with its clients. Before studying the implementation, see in Example 8-14 how the TwilightBus class works from the perspective of a client of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sue', 'Maya', 'Diana']\n"
     ]
    }
   ],
   "source": [
    "class TwilightBus:\n",
    "    \"\"\"A bus model that makes passengers vanish\"\"\"\n",
    "    def __init__(self, passengers=None): \n",
    "        if passengers is None:\n",
    "            self.passengers = [] \n",
    "        else:\n",
    "            self.passengers = passengers \n",
    "    def pick(self, name):\n",
    "        self.passengers.append(name) \n",
    "    def drop(self, name):\n",
    "        self.passengers.remove(name)\n",
    "        \n",
    "basketball_team = ['Sue', 'Tina', 'Maya', 'Diana', 'Pat']\n",
    "bus = TwilightBus(basketball_team)\n",
    "bus.drop('Tina')\n",
    "bus.drop('Pat')\n",
    "print(basketball_team) \n",
    "# Note : when drop from bus it is deleting from basketball_team which is wrong\n",
    "# this is due to wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TwilightBus violates the “Principle of least astonishment”, a best practice of interface design. It surely is astonishing that when the bus drops a student, her name is removed from the basketball team roster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sue', 'Tina', 'Maya', 'Diana', 'Pat']\n",
      "['Sue', 'Maya', 'Diana']\n"
     ]
    }
   ],
   "source": [
    "class TwilightBus:\n",
    "    \"\"\"A bus model that makes passengers vanish\"\"\"\n",
    "    def __init__(self, passengers=None): \n",
    "        if passengers is None:\n",
    "            self.passengers = [] \n",
    "        else:\n",
    "            self.passengers = list(passengers)\n",
    "    def pick(self, name):\n",
    "        self.passengers.append(name) \n",
    "    def drop(self, name):\n",
    "        self.passengers.remove(name)\n",
    "        \n",
    "basketball_team = ['Sue', 'Tina', 'Maya', 'Diana', 'Pat']\n",
    "bus = TwilightBus(basketball_team)\n",
    "bus.drop('Tina')\n",
    "bus.drop('Pat')\n",
    "print(basketball_team) \n",
    "print(bus.passengers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is that the bus is aliasing the list that is passed to the constructor. Instead, it should keep its own passenger list. The fix is simple: in __init__, when the passengers parameter is provided, self.passengers should be initialized with a copy of it, as we did correctly in Example 8-8 (“Deep and shallow copies of arbitrary ob‐ jects” on page 227):\n",
    "```\n",
    "def __init__(self, passengers=None): \n",
    "\n",
    "    if passengers is None:\n",
    "        self.passengers = [] \n",
    "    else:\n",
    "        self.passengers = list(passengers)\n",
    "        ```\n",
    "Make a copy of the passengers list, or convert it to a list if it’s not one.\n",
    "Now our internal handling of the passenger list will not affect the argument used to initialize the bus. As a bonus, this solution is more flexible: now the argument passed to the passengers parameter may be a tuple or any other iterable, like a set or even database results, because the list constructor accepts any iterable. As we create our own list to manage, we make sure that it supports the necessary .remove() and .ap pend() operations we use in the .pick() and .drop() methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### del and garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects are never explicitly destroyed; however, when they become unreachable they may\n",
    "be garbage-collected.\n",
    "\n",
    "The del statement deletes names, not objects. An object may be garbage collected as result of a del command, but only if the variable deleted holds the last reference to the object, or if the object becomes unreachable4. Rebinding a variable may also cause the number of references to an object reach zero, causing its destruction\n",
    "\n",
    "There is a __del__ special method, but it does not cause the dispos‐ al of the instance, and should not be called by your code. __del__ is invoked by the Python interpreter when the instance is about to be destroyed to give it a chance to release external resources. You will seldom need to implement __del__ in your own code, yet some Python beginners spend time coding it for no good reason. The proper use of __del__ is rather tricky. See the __del__ special meth‐ od documentation in the Python data model chapter of the Lan‐ guage Reference.\n",
    "\n",
    "In CPython the primary algorithm for garbage collection is reference counting. Essen‐ tially, each object keeps count of how many references point to it. As soon as that refcount reaches zero, the object is immediately destroyed: CPython calls the __del__ method on the object (if defined) and then frees the memory allocated to the object. In CPython 2.0 a generational garbage collection algorithm was added to detect groups of objects involved in reference cycles — which may be unreachable even with outstanding ref‐ erences to them, when all the mutual references are contained within the group. Other implementations of Python have more sophisticated garbage collector that do not rely of reference counting, which means the __del__ method may not be called immediately when there are no more references to the object. See the PyPy, Garbage Collection, And A Deadlock by A. Jesse Jiryu Davis for discussion of improper and proper use of __del__.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every Python object has an identity, a type and a value. Only the value of an object changes over time9.\n",
    "If two variables refer to immutable objects that have equal values (a == b is True), in practice it rarely matters if they refer to copies or are aliases referring to the same object because the value of an immutable object does not change, with one exception. The exception is immutable collections such as tuples and frozensets: if an immutable col‐ lection holds references to mutable items, then its value may actually change when the value of a mutable item changes. In practice, this scenario is not so common. What never changes in an immutable collection are the identities of the objects within.\n",
    "The fact that variables hold references has many practical consequences in Python pro‐ gramming.\n",
    "1. Simple assignment does not create copies.\n",
    "2. Augmented assignment with +=, *= creates new objects if the left-hand variable is bound to an immutable object, but may modify a mutable object in-place.\n",
    "3. Assigninganewvaluetoanexistingvariabledoesnotchangetheobjectpreviously bound to it. This is called a rebinding: the variable is now bound to a different object. If that variable was the last reference to the previous object, that object will be garbage collected.\n",
    "4. Function parameters are passed as aliases, which means the function may change any mutable object received as an argument. There is no way to prevent this, except making local copies or using immutable objects (eg. passing a tuple instead of a list).\n",
    "5. Using mutable objects as default values for function parameters is dangerous be‐ cause if the parameters are changed in-place then the default is changed, affecting every future call that relies on the default.\n",
    "\n",
    "\n",
    "In CPython, objects are discarded as soon as the number of references to them reaches zero. They may also be discarded if they form groups with cyclic references but no outside references. In some situations it may be useful to hold a reference to an object that will not — by itself — keep an object alive. One example is a class that wants to keep track of all its current instances. This can be done with weak references, a low level mechanism underlying the more useful collections WeakValueDictionary, WeakKey Dictionary, WeakSet, and the finalize function from the weakref module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Pythonic object\n",
    "### Object representations\n",
    "\n",
    "Every object-oriented language has at least one standard way of getting a string repre‐ sentation from any object. Python has two:\n",
    "\n",
    "\n",
    "repr()\n",
    "\n",
    "Return a string representing the object as the developer wants to see it.\n",
    "\n",
    "str()\n",
    "\n",
    "Return a string representing the object as the user wants to see it.\n",
    "As you know, we implement the special methods __repr__ and __str__ to support\n",
    "repr() and str().\n",
    "\n",
    "There are two additional special methods to support alternate representations of objects: __bytes__ and __format__. The __bytes__ method is analogous to __str__: it’s called by bytes() to get the object represented as a byte sequence. Regarding __format__, both the built-in function format() and the str.format() method call it to get string displays of objects using special formatting codes. We’ll cover __bytes__ in the next example, and __format__ after that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classmethod versus staticmethod\n",
    "\n",
    "The classmethod decorator is not mentioned in the Python tutorial and neither is staticmethod. Anyone who has learned OO in Java may wonder why Python has both of these decorators and not just one of them.\n",
    "\n",
    "Let’s start with classmethod. Example 9-3 shows its use: to define a method that operates on the class and not on instances. classmethod changes the way the method is called, so it receives the class itself as the first argument, instead of an instance. Its most com‐ mon use is for alternate constructors, like frombytes in Example 9-3. Note how the last line of frombytes actually uses the cls argument by invoking it to build a new instance: cls(*memv). By convention, the first parameter of a class method should be named cls (but Python doesn’t care how it’s named).\n",
    "\n",
    "In contrast, the staticmethod decorator changes a method so that it receives no special first argument. In essence, a static method is just like a plain function that happens to live in a class body, instead of being defined at the module level. Example 9-4 contrasts the operation of classmethod and staticmethod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class '__main__.Demo'>, 'arg1')\n",
      "('arg2',)\n"
     ]
    }
   ],
   "source": [
    "class Demo:\n",
    "    @classmethod\n",
    "    def class_method(*args):\n",
    "        return args\n",
    "    \n",
    "    @staticmethod\n",
    "    def static_method(*args):\n",
    "        return args\n",
    "    \n",
    "print(Demo.class_method(\"arg1\")) ## Takes class as first argument\n",
    "print(Demo.static_method(\"arg2\")) ## takes \"no class or instance\" as argument...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classmethod decorator is clearly useful, but I’ve never seen a compelling use case for staticmethod. If you want do define a func‐ tion that does not interact with the class, just define it in the mod‐ ule. Maybe the function is closely related even if it never touches the class, so you want to them nearby in the code. Even so, defining the function right before or after the class in the same module is close enough for all practical purposes5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocols and duck typing\n",
    "\n",
    "As early as Chapter 1 we saw that you don’t need to inherit from any special class to create a fully functional sequence type in Python, you just need to implement the meth‐ ods that fulfill the sequence protocol. But what kind of protocol are we talking about?\n",
    "\n",
    "In the context of Object Oriented Programming, a protocol is an informal interface, defined only in documentation and not in code. For example, the sequence protocol in Python entails just the __len__ and __getitem__ methods. Any class Spam that imple‐ ments those methods with the standard signature and semantics can be used anywhere a sequence is expected. Whether Spam is a subclass of this or that is irrelevant, all that matters is that it provides the necessary methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "Card = collections.namedtuple('Card', ['rank', 'suit'])\n",
    "class FrenchDeck:\n",
    "    ranks = [str(n) for n in range(2, 11)] + list('JQKA') \n",
    "    suits = 'spades diamonds clubs hearts'.split()\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._cards)\n",
    "    \n",
    "    def __getitem__(self, position): \n",
    "        return self._cards[position]   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interfaces: from protocols to ABCs\n",
    "\n",
    "Interfaces are the subject of this chapter: from the dynamic protocols that are the hall‐ mark of duck typing to ABCs (Abstract Base Classes) that make interfaces explicit and verify implementations for conformance.\n",
    "\n",
    "If you have a Java, C# or similar background, the novelty here is in the informal protocols of duck typing. But for the long-time Pythonista or Rubyist, that is the “normal” way of thinking about interfaces, and the news is the formality and type-checking of ABCs. The language was 15 years old when ABCs were introduced in Python 2.6.\n",
    "We’ll start the chapter reviewing how the Python community traditionally understood interfaces as somewhat loose — in the sense that a partially implemented interface is often acceptable. We’ll make that clear through a couple examples that highlight the dynamic nature of duck typing.\n",
    "\n",
    "Then, a guest essay by Alex Martelli will introduce ABCs and give name to a new trend in Python programming. The rest of the chapter will be devoted to ABCs, starting with their common use as superclasses when you need to implement an interface. We’ll then see when an ABC checks concrete subclasses for conformance to the interface it defines, and how a registration mechanism lets developers declare that a class implements an interface without subclassing. Finally, we’ll see how an ABC can be programmed to automatically “recognize” arbitrary classes that conform to its interface — without sub‐ classing or explicit registration.\n",
    "\n",
    "We will implement a new ABC to see how that works, but Alex Martelli and I don’t want to encourage you to start writing your own ABCs left and right. The risk of over- engineering with ABCs is very high.\n",
    "\n",
    "ABCs, like descriptors and metaclasses, are tools for building frame‐ works. Therefore, only a very small minority of Python developers can create ABCs without imposing unreasonable limitations and needless work on fellow programmers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interfaces and protocols in Python culture\n",
    "Python was already highly successful before ABCs were introduced, and most existing code does not use them at all. Since Chapter 1 we’ve been talking about duck typing and protocols. In “Protocols and duck typing” on page 281 protocols are defined as the informal interfaces that make polymorphism work in languages with dynamic typing like Python.\n",
    "\n",
    "How do interfaces work in a dynamic-typed language? First, the basics: even without an interface keyword in the language, and regardless of ABCs, every class has an interface: the set public attributes (methods or data attributes) implemented or inherited by the class. This includes special methods, like __getitem__ or __add__.\n",
    "By definition, protected and private attributes are not part of an interface, even if “pro‐ tected” is merely a naming convention (the single leading underscore) and private at‐ tributes are easily accessed (recall “Private and “protected” attributes in Python” on page 263). It is bad form to violate these conventions.\n",
    "\n",
    "On the other hand, it’s not a sin to have public data attributes as part of the interface of an object, because — if necessary — a data attribute can always be turned into a property implementing getter/setter logic without breaking client code that uses the plain obj.attr syntax\n",
    "\n",
    "A useful complementary definition of interface is: the subset of an object’s public meth‐ ods that enable it to play a specific role in the system. That’s what is implied when the Python documentation mentions “a file-like object” or “an iterable”, without specifying a class. An interface seen as a set of methods to fulfill a role is what Smalltalkers called a procotol, and the term spread to other dynamic language communities. Protocols are independent of inheritance. A class may implement several protocols, enabling its in‐ stances to fulfill several roles.\n",
    "\n",
    "Protocols are interfaces, but because they are informal — defined only by documenta‐ tion and conventions — protocols cannot be enforced like formal interfaces can (we’ll see how ABCs enforce interface conformance later in this chapter). A protocol may be partially implemented in a particular class, and that’s OK. Sometimes all a specific API requires from “a file-like object” is that it has a .read() method that returns bytes. The remaining file methods may or may not be relevant in the context.\n",
    "\n",
    "As I write this, the Python 3 documentation of memoryview says that it works with objects that “support the buffer protocol”, which is only documented at the C API level. The bytearray constructor accepts an “an object conforming to the buffer interface”.\n",
    "\n",
    "there is a move to adopt “bytes-like object” as a friendlier term2. I point this out to emphasize that “X-like object”, “X protocol” and “X interface” are synonyms in the minds of Pythonistas.\n",
    "\n",
    "One of the most fundamental interfaces in Python is the sequence protocol. The inter‐ preter goes out of its way to handle objects that provide even a minimal implementation of that protocol, as the next section demonstrates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monkey-patching to implement a protocol at run time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FrenchDeck class from Example 11-4 has a major flaw: it cannot be shuffled. Years ago when I first wrote the FrenchDeck example I did implement a shuffle method. Later I had a Pythonic insight: if a FrenchDeck acts like a sequence, then it doesn’t need its own shuffle method, because there is already random.shuffle, documented as “Shuffle the sequence x in place”.\n",
    "\n",
    "When you follow established protocols you improve your chances of leveraging existing standard library and third-party code, thanks to duck typing.\n",
    "The standard random.shuffle function is used like this:\n",
    "```\n",
    ">>> from random import shuffle >>> l = list(range(10))\n",
    ">>> shuffle(l)\n",
    ">>> l\n",
    "    [5, 2, 9, 7, 8, 3, 1, 4, 0, 6]\n",
    "However, if we try to shuffle a FrenchDeck instance, we get an exception, as in Example 11-5.\n",
    "Example 11-5. random.shuffle cannot handle FrenchDeck.\n",
    ">>> from random import shuffle\n",
    ">>> from frenchdeck import FrenchDeck >>> deck = FrenchDeck()\n",
    ">>> shuffle(deck)\n",
    "Traceback (most recent call last):\n",
    "  File \"<stdin>\", line 1, in <module>\n",
    "  File \".../python3.3/random.py\", line 265, in shuffle\n",
    "    x[i], x[j] = x[j], x[i]\n",
    "TypeError: 'FrenchDeck' object does not support item assignment\n",
    "```\n",
    "The error message is quite clear: \"'FrenchDeck' object does not support item assign‐ ment”. The problem is that shuffle operates by swapping items inside the collection, and FrenchDeck only implements the immutable sequence protocol. Mutable sequences must also provide a __setitem__ method.\n",
    "\n",
    "Because Python is dynamic, we can fix this at runtime, even at the interactive console. Here is how to do it:\n",
    "Example 11-6. Monkey patching FrenchDeck to make it mutable and compatible with random.shuffle (continuing from Example 11-5).\n",
    "\n",
    "```\n",
    ">>> def set_card(deck, position, card): ... deck._cards[position] = card ...\n",
    ">>> FrenchDeck.__setitem__ = set_card >>> shuffle(deck)\n",
    ">>> deck[:5]\n",
    "[Card(rank='3', suit='hearts'), Card(rank='4', suit='diamonds'), Card(rank='4', suit='clubs'), Card(rank='7', suit='hearts'), Card(rank='9', suit='spades')]\n",
    "\n",
    "```\n",
    "\n",
    "create a function that takes deck, position and card as arguments.\n",
    "assign that function to an attribute named __setitem__ in the FrenchDeck class.\n",
    "\n",
    "deck can now be sorted because FrenchDeck now implements the necessary method of the mutable sequence protocol.\n",
    "The signature of the __setitem__ special method is defined in the Emulating container types section of the Data model chapter of the Python Language Reference. Here we named the arguments deck, position, card — and not self, key, value as in the Language Reference — to show that every Python method starts life as a plain function, and naming the first argument self is merely a convention. This is OK in a console session, but in a Python source file it’s much better to use self, key and value as doc‐ umented.\n",
    "\n",
    "The trick is that set_card knows that the deck object has an attribute named _cards, and _cards must be a mutable sequence. The set_card function is then attached to the FrenchDeck class as the __setitem__ special method. ** This is an example of monkey patching: changing a class or module at run time, without touching the source code. Monkey patching is powerful, but the code that does the actual patching is very tightly coupled with the program to be patched, often handling private and undocumented parts.**\n",
    "\n",
    "Besides being an example of monkey patching, Example 11-6 highlights that protocols are dynamic: random.shuffle doesn’t care what type of argument it gets, it only needs the object to implement part of the mutable sequence protocol. It doesn’t even matter if the object was “born” with the necessary methods or if they were somehow acquired later.\n",
    "The theme of this chapter so far has been “duck typing”: operating with objects regardless of their types, as long as they implement certain protocols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duck Typing  by Alex Martelli\n",
    "\n",
    "I’ve been credited on Wikipedia for helping spread the helpful meme and sound-bite \"duck typing“ — i.e, ignoring an object’s actual type, focusing instead on ensuring that the object implements the method names, signatures, and semantics, required for its intended use.\n",
    "\n",
    "In Python, this mostly boils down to avoiding the use of isinstance to check the object’s type (not to mention the even worse approach of checking, e.g, whether type(foo) is bar — which is rightly anathema as it inhibits even the simplest forms of inheritance!).\n",
    "\n",
    "The overall duck typing approach remains quite useful in many contexts — and yet, in many others, an often preferable one has evolved over time. And herein lies a tale...\n",
    "\n",
    "In recent generations, the taxonomy of genus and species (including but not limited to the family of waterfowl known as Anatidae) has mostly been driven by phenetics — an approach focused on similarities of morphology and behavior... chiefly, observable traits. The analogy to “duck typing” was strong.\n",
    "\n",
    "However, parallel evolution can often produce similar traits, both morphological and behavioral ones, among species that are actually unrelated, but just happened to evolve in similar, though separate, ecological niches. Similar “accidental similarities” happen in programming, too — e.g, consider the classic OOP example:\n",
    "\n",
    "```\n",
    "class Artist:\n",
    "def draw(self): ...\n",
    "\n",
    "class Gunslinger:\n",
    "def draw(self): ...\n",
    "\n",
    "class Lottery:\n",
    "def draw(self): ...\n",
    "\n",
    "```\n",
    "\n",
    "Clearly, the mere existence of a method called draw, callable without arguments, is far from sufficient to assure us that two objects x and y such that x.draw() and y.draw() can be called are in any way exchangeable or abstractly equivalent — nothing about the similarity of the semantics resulting from such calls can be inferred. Rather, we need a knowledgeable programmer to somehow positively assert that such an equivalence holds at some level!\n",
    "\n",
    "In biology (and other disciplines) this issue has led to the emergence (and, on many facets, the dominance) of an approach that’s an alternative to phenetics, known as cladistics — focusing taxonomical choices on characteristics that are inherited from common ancestors, rather than ones that are independently evolved. (Cheap and rapid DNA sequencing can make cladistics highly practical in many more cases, in recent years).\n",
    "\n",
    "For example, sheldgeese (once classified as being closer to other geese) and shelducks (once classified as being closer to other ducks) are now grouped together within the subfamily Tadornidae (implying they’re closer to each other than to any other Anati‐ dae — sharing a closer common ancestor). Furthermore, DNA analysis has shown, in particular, that the White-winged Wood Duck is not as close to the Muscovy Duck (the latter being a shelduck) as similarity in looks and behavior had long suggested — so the wood duck was reclassified into its own genus, and entirely out of the subfamily!\n",
    "\n",
    "Does this matter? It depends on the context! For such purposes as deciding how best to cook a waterfowl once you’ve bagged it, for example, specific observable traits (not all of them — plumage, for example, is de minimis in such a context :-), mostly texture and flavor (old-fashioned phenetics!), may be far more relevant than cladistics. But for other issues, such as susceptibility to different pathogens (whether you’re trying to raise wa‐ terfowl in captivity, or preserve them in the wild), DNA closeness can matter much more...\n",
    "So, by very loose analogy with these taxonomic revolutions in the world of waterfowls, I’m recommending supplementing (not entirely replacing — in certain contexts it shall still serve) good old duck typing with... goose typing!\n",
    "What goose typing means is: isinstance(obj, cls) is now just fine... as long as cls is an Abstract Base Class — in other words, cls’s metaclass is abc.ABCMeta.\n",
    "\n",
    "You can find many useful existing abstract classes in collections.abc — others yet in the numbers module of the Python Standard Library3.\n",
    "\n",
    "Among the many conceptual advantages of ABCs over concrete classes (such as, Scott Meyer’s “all non-leaf classes should be abstract\" — see Item 33 in his book, More Effective C++), Python’s ABCs add one major practical advantage: the register class method, which lets end-user code “declare” that a certain class becomes a “virtual” subclass of an ABC (for this purpose the registered class must meet the ABC’s method name and signature requirements, and more importantly the underlying semantic contract — but it need not have been developed with any awareness of the ABC, and in particular need not inherit from it!). This goes a long way towards breaking the rigidity and strong coupling that make inheritance something to use with much more caution than typically practiced by most OOP programmers...\n",
    "Sometimes you don’t even need to register a class for an ABC to recognize it as a subclass!\n",
    "That’s the case for the ABCs whose essence boils down to a few special methods. For example:\n",
    "\n",
    "```\n",
    ">>> class Struggle:\n",
    "... def __len__(self): return 23 ...\n",
    ">>> from collections import abc\n",
    ">>> isinstance(Struggle(), abc.Sized) True\n",
    "```\n",
    "\n",
    "As you see, abc.Sized recognizes Struggle as “a subclass”, with no need for registra‐ tion — because implementing the special method named __len__ is all it takes (it’s sup‐ posed to be implemented with the proper syntax — callable without arguments — and semantics — returning a non-negative integer denoting an object’s “length”; any code that implements a specially named method, such as __len__, with arbitrary, non- compliant syntax and semantics has much-worse problems anyway :-).\n",
    "\n",
    "So, here’s my valediction...: whenever you’re implementing a class embodying any of the concepts represented in the ABCs in numbers, collections.abc, or other frame‐ work you may be using, be sure (if needed) to subclass it from, or register it into, the corresponding ABC. At the start of your programs using some library or framework defining classes which have omitted to do that, perform the registrations yourself; then, when you must check for (most typically) an argument being, e.g, “a sequence”, check whether:\n",
    "\n",
    "    isinstance(the_arg, collections.abc.Sequence)\n",
    "    \n",
    "    \n",
    "And, don’t define custom ABCs (or metaclasses) in production code... if you feel the urge to do so, I’d bet it’s likely to be a case of “all problems look like a nail”-syndrome for somebody who just got a shiny new hammer — you (and future maintainers of your code) will be much happier sticking with straightforward and simple code, eschewing such depths. Valē!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subclassing an ABC\n",
    "\n",
    "Following Martelli’s advice we’ll leverage an existing ABC, collections.MutableSe quence, before daring to invent our own. In Example 11-8 FrenchDeck2 is explicitly declared a sub-class of collections.MutableSequence.\n",
    "\n",
    "\n",
    "Python does not check for the implementation of the abstract methods at import time (when the frenchdeck2.py module is loaded and compiled), but only at runtime when we actually try to instantiate FrenchDeck2. Then, if we fail to implement any abstract\n",
    "\n",
    "method we get a TypeError exception with a message such as \"Can't instantiate abstract class FrenchDeck2 with abstract methods __delitem__, insert\". That’s why we must implement __delitem__ and insert, even if our FrenchDeck2 examples to not need those behaviors: the MutableSequence ABC demands them.\n",
    "\n",
    "As Figure 11-2 shows, not all methods of the Sequence and MutableSequence ABCs are abstract. From Sequence, FrenchDeck2 inherits the ready-to-use concrete methods __contains__, __iter__, __reversed__, index, and count; from MutableSequence, it gets append, reverse, extend, pop, remove, and __iadd__.\n",
    "The concrete methods in each collections.abc ABC are implemented in terms of the public interface of the class, so they work without any knowledge of the internal struc‐ ture of instances.\n",
    "\n",
    "As the coder of a concrete subclass, you may be able to override methods inherited from ABCs with more efficient implementations. For example, __contains__ works by doing a full scan of the se‐ quence, but if your concrete sequence keeps its items sorted, you can write a faster __contains__ that does a binary search using bisect function (see “Managing ordered sequences with bisect” on page 44).\n",
    "\n",
    "To use ABCs well you need to know what’s available. We’ll go over the collections ABCs next.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "Card = collections.namedtuple('Card', ['rank', 'suit'])\n",
    "class FrenchDeck2(collections.MutableSequence):\n",
    "    ranks = [str(n) for n in range(2, 11)] + list('JQKA') \n",
    "    suits = 'spades diamonds clubs hearts'.split()\n",
    "    def __init__(self):\n",
    "        self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks]\n",
    "    def __len__(self):\n",
    "        return len(self._cards)\n",
    "    def __getitem__(self, position): \n",
    "        return self._cards[position]\n",
    "    def __setitem__(self, position, value): # \n",
    "        self._cards[position] = value\n",
    "    def __delitem__(self, position): # \n",
    "        del self._cards[position]\n",
    "    def insert(self, position, value): # \n",
    "        self._cards.insert(position, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this chapter was to travel from the highly dynamic nature of informal in‐ terfaces — called protocols — visit the static interface declarations of ABCs, and con‐ clude with the dynamic side of ABCs: virtual subclasses and dynamic subclass detection with __subclasshook__.\n",
    "\n",
    "We started the journey reviewing the traditional understanding of interfaces in the Python community. For most of the history of Python, we’ve been mindful of interfaces, but they were informal like the protocols from Smalltalk, and the official docs used language such as “foo protocol”, “foo interface”, and “foo-like object” interchangeably. Protocol-style interfaces have nothing to do with inheritance; each class stands alone when implementing a protocol. That’s how interfaces look like when you embrace duck typing.\n",
    "\n",
    "With Example 11-3 we observed how deeply Python supports the sequence protocol. If a class implements __getitem__ and nothing else, Python manages to iterate over it, and the in operator just works. We then went back to the old FrenchDeck example of Chapter 1 to support shuffling by dynamically adding a method. This illustrated monkey patching and emphasized the dynamic nature of protocols. Again we saw how a partially\n",
    "\n",
    "implemented protocol can be useful: just adding __setitem__ from the mutable se‐ quence protocol allowed us to leverage a ready-to-use function from the standard li‐ brary: random.shuffle. Being aware of existing protocols let’s us make the most of the rich Python Standard library.\n",
    "\n",
    "Alex Martelli then introduced the term “goose typing16\" to describe a new style of Python programming. With “goose typing”, ABCs are used to make interfaces explicit and classes may claim to implement an interface by subclassing an ABC or by registering with it — without requiring the strong and static link of an inheritance relationship.\n",
    "The FrenchDeck2 example made clear the main drawbacks and advantages of explicit ABCs. Inheriting from abc.MutableSequence forced us to implement two methods we did not really need: insert and __delitem__. On the other hand, even a Python newbie can look at a FrenchDeck2 and see that it’s a mutable sequence. And, as bonus, we inherited eleven ready-to-use methods from abc.MutableSequence (five indirectly from abc.Sequence).\n",
    "\n",
    "After a panoramic view of existing ABCs from collections.abc in Figure 11-3, we wrote an ABC from scratch. Doug Hellmann, creator of the cool PyMOTW.com (Python Module of the Week) explains the motivation:\n",
    "By defining an abstract base class, a common API can be established for a set of subclasses. This capability is especially useful in situations where someone less familiar with the source for an application is going to provide plug-in extensions...17\n",
    "\n",
    "Putting the Tombola ABC to work, we created three concrete subclasses: two inheriting from Tombola, the other a virtual subclass registered with it. All passing the same suite of tests.\n",
    "\n",
    "To close the chapter, we mentioned how several built-in types are registered to ABCs in the collections.abc module so you can ask isinstance(memoryview, abc.Se quence) and get True, even if memoryview does not inherit from abc.Sequence. And finally we went over the __subclasshook__ magic which lets an ABC recognize any unregistered class as a subclass, as long as it passes a test that can be as simple or as complex as you like — the examples in the Standard Library merely check for method names.\n",
    "\n",
    "In conclusion, I’d like to restate Alex Martelli’s admonition that we should refrain from creating our own ABCs, except when we are building user-extensible frameworks — which most of the time we are not. On a daily basis, our contact with ABCs should be subclassing or registering classes with existing ABCs. Less often than subclassing or\n",
    "\n",
    "registering, we might use ABCs for isinstance checks. And even more rarely — if ever — we find occasion to write a new ABC from scratch.\n",
    "After 15 years of Python, the first abstract class I ever wrote that is not a didactic example was the Board class of the Pingo project. The drivers that support different single board computers and controllers are subclasses of Board, thus sharing the same interface. In reality, although conceived and implemented as an abstract class, the pingo.Board class does not subclass abc.ABC as I write this18. I intend to make Board an explicit ABC eventually — but there are more important things to do in the project.\n",
    "\n",
    "Here is a fitting quote to end this chapter:\n",
    "Although ABCs facilitate type checking, it’s not something that you should overuse in a program. At its heart, Python is a dynamic language that gives you great flexibility. Trying to enforce type constraints everywhere tends to result in code that is more complicated than it needs to be. You should embrace Python’s flexibility19.\n",
    "— David Beazley and Brian Jones\n",
    "Python Cookbook 3ed.\n",
    "\n",
    "Or, as technical reviewer Leonardo Rochael wrote: “If you feel tempted to create a cus‐ tom ABC, please first try to solve your problem through regular duck-typing”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soapbox\n",
    "\n",
    "Soapbox\n",
    "Type hints\n",
    "Probably the biggest news in the Python world in 2014 was that Guido van Rossum gave a green light to the implementation of optional static type checking using function an‐ notations, similar to what the Mypy checker does. This happened in the Python-ideas mailing-list on August 15. The message is Optional static typing — the crossroads. The next month, PEP 484 - Type Hints was published as a draft, authored by Guido.\n",
    "The idea is to let programmers optionally use annotations to declare parameter and return types in function definitions. The key word here is “optionally”. You’d only add such annotations if you want the benefits and constraints that come with them, and you could put them in some functions but not in others.\n",
    "On the surface this may sound like what Microsoft did with with TypeScript, their Java‐ Script superset, except that TypeScript goes much further: it adds new language con‐ structs (e.g. modules, classes, explicit interfaces etc.), allows typed variable declarations and actually compiles down to plain JavaScript. As of this writing (September, 2014), the goals of optional static typing in Python are much less ambitious.\n",
    "To understand the reach of this proposal, there is a key point that Guido makes in the historic August 15, 2014, e-mail:\n",
    "I am going to make one additional assumption: the main use cases will be linting, IDEs, and doc generation. These all have one thing in common: it should be possible to run a program even though it fails to type check. Also, adding types to a program should not hinder its performance (nor will it help :-).\n",
    "￼￼￼￼344 | Chapter 11: Interfaces: from protocols to ABCs\n",
    "So, it seems this is not such a radical move as it seems at first. PEP 482 - Literature Overview for Type Hints is referenced by PEP 484 - Type Hints, and briefly documents type hints in third-party Python tools and in other languages.\n",
    "Radical or not, type hints are upon us: support for PEP 484 in the form of a typing module is likely to land in Python 3.5 already. The way the proposal is worded and implemented makes it clear that no existing code will stop running because of the lack of type hints — or their addition, for that matter.\n",
    "Finally, PEP 484 clearly states:\n",
    "It should also be emphasized that Python will remain a dynamically typed language, and the authors have no desire to ever make type hints mandatory, even by convention.\n",
    "Is Python weakly typed?\n",
    "Discussions about language typing disciplines are sometimes confused due to lack of a uniform terminology. Some writers (like Bill Venners in the interview with Guido men‐ tioned in Further Reading), say that Python has weak typing, which puts it into the same category of JavaScript and PHP. A better way of talking about typing discipline is to consider two different axes:\n",
    "Strong versus weak typing\n",
    "If the language rarely performs implicit conversion of types, it’s considered strongly typed; if it often does it, it’s weakly typed. Java, C++ and Python are strongly typed. PHP, JavaScript and Perl are weakly typed.\n",
    "Static versus dynamic typing\n",
    "If type-checking is performed at compile time, the language is statically typed; it it happens at run-time, it’s dynamically typed. Static typing requires type declarations (some modern languages use type inference to avoid some of that). Fortran and Lisp are the two oldest programming languages still alive and they use, respectively, static and dynamic typing.\n",
    "Strong typing helps catch bugs early. Below are some examples of why weak typing is bad20.\n",
    "    // this is JavaScript (tested with Node.js v0.10.33)\n",
    "￼￼'' == '0'\n",
    "0 == ''\n",
    "0 == '0'\n",
    "'' < 0\n",
    "'' < '0'\n",
    "// false\n",
    "// true\n",
    "// true\n",
    "// false\n",
    "// true\n",
    "Python does not perform automatic coercion between strings and numbers, so the == expressions above all result False — preserving the the transitivity of == — and the < comparisons raise TypeError in Python 3.\n",
    "20. Adapted from Douglas Crockford’s JavaScript: The Good Parts (O’Reilly, 2008), Appendix B, p. 109\n",
    "Further reading | 345\n",
    "￼\n",
    "Static typing makes it easier for tools (compilers, IDEs) to analyze code to detect errors and provide other services (optimization, refactoring etc.). Dynamic typing increases opportunities for reuse, reducing line count, and allows interfaces to emerge naturally as protocols, instead of being imposed early on.\n",
    "To summarize, Python uses dynamic and strong typing. PEP 484 - Type Hints will not change that, but will allow API authors to add optional type annotations so that tools can perform some static type checking.\n",
    "Monkey patching\n",
    "Monkey patching has a bad reputation. If abused, it can lead to systems that are hard to understand and maintain. The patch is usually tightly coupled with its target, making it brittle. Another problem is that two libraries that apply monkey-patches may step on each other’s toes, with the second library to run destroying patches of the first.\n",
    "But monkey patching can also be useful, for example, to make a class implement a protocol at runtime. The adapter design pattern solves the same problem by imple‐ menting a whole new class.\n",
    "It’s easy to monkey patch Python code, but there are limitations. Unlike Ruby and Java‐ Script, Python does not let you monkey patch the built-in types. I actually consider this an advantage, since you can be certain that a str object will always have those same methods. This limitation reduces the chance that external libraries try to apply con‐ flicting patches.\n",
    "Interfaces in Java, Go and Ruby\n",
    "Since C++ 2.0 (1989), abstract classes have been used to specify interfaces that language. The designers of Java opted not to have multiple inheritance of classes, which precluded the use of abstract classes as interface specifications — because often a class needs to implement more than one interface. But they added the interface as a language con‐ struct, and a class can implement more than one interface — a form of multiple inher‐ itance. Making interface definitions more explicit than ever was a great contribution of Java. With Java 8, an interface can provide method implementations, called Default Methods. With this, Java interfaces became closer to abstract classes in C++ and Python.\n",
    "The Go language has a completely different approach. First of all, there is no inheritance in Go. You can define interfaces, but you don’t need (and you actually can’t) explicitly say that a certain type implements an interface. The compiler determines that automat‐ ically. So what they have in Go could be called “static duck typing”, in the sense that interfaces are checked at compile time but what matters is what types actually imple‐ ment.\n",
    "Compared to Python, it’s as if, in Go, every ABC implemented the __subclasshook__ checking function names and signatures, and you never subclassed or registered an ABC. If we wanted Python to look more like Go, we would have to perform type checks on all function arguments. Some of the infrastructure is available (recall “Function an‐ notations” on page 154). Guido has already said he thinks it’s OK to use those annota‐\n",
    "￼￼￼346 | Chapter 11: Interfaces: from protocols to ABCs\n",
    "tions for type checking — at least in support tools. See “Soapbox” on page 163 in Chap‐ ter 5 for more about this.\n",
    "Rubyists are firm believers in duck typing, and Ruby has no formal way to declare an interface or an abstract class, except to do the same we did in Python prior to 2.6: raise NotImplementedError in the body of methods to make them abstract by forcing the user to subclass and implement them.\n",
    "Meanwhile, I read that Yukihiro “Matz” Matsumoto, creator of Ruby, said in a keynote in September, 2014, that static typing may be in the future of the language. That was at Ruby Kaigi in Japan, one of the most important Ruby conferences every year. As I write this I haven’t seen a transcript, but Godfrey Chan posted about it in his blog: Ruby Kaigi 2014: Day 2. From Chan’s report, it seems Matz focused on function annotations. There is even mention of Python function annotations.\n",
    "I wonder if function annotations would be really good without ABCs to add structure to the type system without losing flexibility. So maybe formal interfaces are also in the future of Ruby.\n",
    "I believe Python ABCs, with the register function and __subclasshook__, brought formal interfaces to the language without throwing away the advantages of dynamic typing.\n",
    "Perhaps the geese are poised to overtake the ducks.\n",
    "Metaphors and idioms in interfaces\n",
    "A metaphor fosters understanding by making constraints clear. That’s the value of the words “stack” and “queue” in describing those fundamental data structures: they make clear how items can be added or removed. On the other hand, Alan Cooper writes in About Face, 4e (Wiley, 2014):\n",
    "Strict adherence to metaphors ties interfaces unnecessarily tightly to the workings of the physical world.\n",
    "He’s referring to user interfaces, but the admonition applies to APIs as well. But Cooper does grant that when an “truly appropriate” metaphor “falls on our lap”, we can use it (he writes “falls on our lap” because it’s so hard to find fitting metaphors that you should not spend time actively looking for them). I believe the bingo machine imagery I used in this chapter is appropriate and I stand by it.\n",
    "About Face is by far the best book about UI design I’ve read — and I’ve read a few. Letting go of metaphors as a design paradigm, and replacing it with “idiomatic interfaces” was the most valuable thing I learned from Cooper’s work. As mentioned, Cooper does not deal with APIs, but the more I think about his ideas, the more I see they apply to Python. The fundamental protocols of the language are what Cooper calls “idioms”. Once we learn what a “sequence” is we can apply that knowledge in different contexts. This is a main theme of Fluent Python: highlighting the fundamental idioms of the language, so your code is concise, effective and readable — for a fluent Pythonista."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inheritance: for good or for worse\n",
    "\n",
    "This chapter is about inheritance and subclassing, with emphasis on two particulars that are very specific to Python:\n",
    "• The pitfalls of subclassing from built-in types.\n",
    "• Multiple inheritance and the method resolution order.\n",
    "\n",
    "Many consider multiple inheritance more trouble than it’s worth. The lack of it certainly did not hurt Java; it probably fueled its widespread adoption after many were trauma‐ tized by the excessive use of multiple inheritance in C++.\n",
    "\n",
    "However, the amazing success and influence of Java means that a lot of programmers come to Python without having seen multiple inheritance in practice. This is why, in‐ stead of toy examples, our coverage of multiple inheritance will be illustrated by two important Python projects: the Tkinter GUI toolkit and the Django Web framework.\n",
    "We’ll start with the issue of subclassing built-ins. The rest of the chapter will cover multiple inheritance with our case studies and discuss good and bad practices when building class hierarchies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subclassing built-in types is tricky\n",
    "\n",
    "Before Python 2.2 it was not possible to subclass built-in types such as list or dict. Since then, it can be done but there is a major caveat: the code of the built-ins (written in C) does not call special methods overridden by user-defined classes.\n",
    "\n",
    "A good short description of the problem is in the documentation for PyPy, in Differences between PyPy and CPython, section Subclasses of built-in types:\n",
    "Officially, CPython has no rule at all for when exactly overridden method of subclasses of built-in types get implicitly called or not. As an approximation, these methods are never called by other built-in methods of the same object. For example, an overridden __getitem__() in a subclass of dict will not be called by e.g. the built-in get() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'one': 1}\n",
      "{'one': 1, 'two': [2, 2]}\n",
      "{'one': 1, 'two': [2, 2], 'three': 3}\n"
     ]
    }
   ],
   "source": [
    "class DoppelDict(dict):\n",
    "    def __setitem__(self, key, value):\n",
    "        super().__setitem__(key, [value] * 2)\n",
    "\n",
    "dd = DoppelDict(one=1)\n",
    "print(dd)\n",
    "dd['two'] = 2\n",
    "print(dd)\n",
    "dd.update(three=3)\n",
    "print(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you observe dict - update and init are not calling the customized setitem but using default one\n",
    "\n",
    "This built-in behavior is a violation of a basic rule of object oriented programming: the search for methods should always start from the class of the target instance (self), even when the call happens inside a method implemented in a superclass. In this sad state of\n",
    "\n",
    "affairs, the __missing__ method — which we saw in “The __missing__ method” on page 72 — works as documented only because it’s handled as a special case.\n",
    "The problem is not limited to calls within an instance, i.e. whether self.get() calls self.__getitem__(), but also happens with overridden methods of other classes that should be called by the built-in methods. Here is an example adapted from the PyPy documentation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'one': [1, 1]}\n",
      "{'one': [1, 1], 'two': [2, 2]}\n",
      "{'one': [1, 1], 'two': [2, 2], 'three': [3, 3]}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "class DoppelDict2(collections.UserDict):\n",
    "    def __setitem__(self, key, value):\n",
    "        super().__setitem__(key, [value] * 2)\n",
    "\n",
    "dd = DoppelDict2(one=1)\n",
    "print(dd)\n",
    "dd['two'] = 2\n",
    "print(dd)\n",
    "dd.update(three=3)\n",
    "print(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize: the problem described in this section applies only to method delegation within the C language implementation of the built-in types, and only affects user- defined classes derived directly from those types. If you subclass from a class coded in Python, such as UserDict or MutableMapping, you will not be troubled by this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Distinguish interface inheritance from implementation inheritance\n",
    "When dealing with multiple inheritance it’s useful to keep straight the reasons why subclassing is done in the first place. The main reasons are:\n",
    "• Inheritance of interface: creates a sub-type, implying an “is-a” relationship. • Inheritance of implementation: avoids code duplication by reuse.\n",
    "In practice both uses are often simultaneous, but whenever you can make the intent clear, do it. Inheritance for code reuse is an implementation detail, and it can often be replaced by composition and delegation. On the other hand, interface inheritance is the backbone of a framework.\n",
    "2. Make interfaces explicit with ABCs\n",
    "In modern Python, if a class is designed to define an interface, it should be an explicit ABC. In Python ≥ 3.4 this means: subclass abc.ABC or another ABC (see “ABC syntax details” on page 330 if you need to support older Python versions).\n",
    "3. Use mixins for code reuse\n",
    "If a class is designed to provide method implementations for reuse by multiple unrelated subclasses, without implying an “is-a” relationship, it should be an explicit mixin class. Conceptually, a mixin does not define a new type, it merely bundles methods for reuse. A mixin should never be instantiated, and concrete classes should not inherit only from a mixin. Each mixin should provide a single specific behavior, implementing few and very closely related methods.\n",
    "4. Make mixins explicit by naming\n",
    "There is no formal way in Python to state that a class is a mixin, so it is highly recom‐ mended that they are named with a ...Mixin suffix. Tkinter does not follow this advice, but if it did, XView, would be XViewMixin, Pack would be PackMixin and so on with all the classes where I put the «mixin» tag Figure 12-3.\n",
    "5. An ABC may also be a mixin; the reverse is not true\n",
    "Since an ABC can implement concrete methods, it works as a mixin as well. An ABC also defines a type, which a mixin does not. And an ABC can be the sole base class of\n",
    "￼Coping with multiple inheritance | 361\n",
    "any another class, while a mixin should never be subclassed alone except by another, more specialized mixin — not a common arrangement in real code.\n",
    "One restriction applies to ABCs and not to mixins: the concrete methods implemented in an ABC should only collaborate with methods of the same ABC and its superclasses. This implies that concrete methods in an ABC are always for convenience, because everything they do an user of the class can also do by calling other methods of the ABC.\n",
    "6. Don’t subclass from more than one concrete class\n",
    "Concrete classes should have zero or at most one concrete superclass6. In other words, all but one of the superclasses of a concrete class should be ABCs or mixins. For example, in the code below, if Alpha is a concrete class, then Beta and Gamma must be ABCs or mixins:\n",
    "class MyConcreteClass(Alpha, Beta, Gamma):\n",
    "\"\"\"This is a concrete class: it can be instantiated.\"\"\" # ... more code ...\n",
    "7. Provide aggregate classes to users\n",
    "If some combination of ABCs or mixins is particularly useful to client code, provide a class that brings them together in a sensible way. Grady Booch calls this an aggregate class.7\n",
    "For example, here is the complete source code for tkinter.Widget: class Widget(BaseWidget, Pack, Place, Grid):\n",
    "        \"\"\"Internal class.\n",
    "Base class for a widget which can be positioned with the geometry managers Pack, Place or Grid.\"\"\"\n",
    "pass\n",
    "The body of Widget is empty, but the class provides a useful service: it brings together four superclasses so that anyone who needs to create a new widget does not need re‐ member all those mixins, or wonder if they need to be declared in a certain order in a class statement. A better example of this is the Django ListView class, which we’ll discuss shortly, in “A modern example: mixins in Django generic views” on page 364.\n",
    "6. In “Waterfowl and ABCs” on page 316, Alex Martelli quotes Scott Meyer’s More Effective C++ which goes even further: “all non-leaf classes should be abstract” i.e. concrete classes should not have concrete super‐ classes at all.\n",
    "7. “Aclassthatisconstructedprimarilybyinheritingfrommixinsanddoesnotadditsownstructureorbehavior is called an aggregate class.”, Grady Booch et.al. — Object Oriented Analysis and Design, 3e (Addison-Wesley, 2007), p. 109.\n",
    "￼362 | Chapter 12: Inheritance: for good or for worse\n",
    "8. “Favor object composition over class inheritance.”\n",
    "This quote comes straight the Design Patterns book8, and is the best advice I can offer here. Once you get comfortable with inheritance, it’s too easy to overuse it. Placing objects in a neat hierarchy appeals to our sense of order; programmers do it just for fun.\n",
    "However, favoring composition leads to more flexible designs. For example, in the case of the tkinter.Widget class, instead of inheriting the methods from all geometry man‐ agers, widget instances could hold a reference to a geometry manager, and invoke its methods. After all, a Widget should not “be” a geometry manager, but could use the services of one via delegation. Then you could add a new geometry manager without touching the widget class hierarchy and without worrying about name clashes. Even with single inheritance, this principle enhances flexibility, because subclassing is a form of tight coupling, and tall inheritance trees tend to be brittle.\n",
    "Composition and delegation can replace the use of mixins to make behaviors available to different classes, but cannot replace the use of interface inheritance to define a hier‐ archy of types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A modern example: mixins in Django generic views\n",
    "\n",
    "In Django, a view is a callable object that takes, as argument, an object representing an HTTP request and returns an object representing an HTTP response. The different responses are what interests us in this discussion. They can be as simple as a redirect response, with no content body, or as complex as a catalog page in an online store, rendered from an HTML template and listing multiple merchandise with buttons for buying and links to detail pages.\n",
    "Originally, Django provided a set of functions, called generic views, that implemented some common use cases. For example, many sites need to show search results that\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators as coroutines\n",
    "\n",
    "About five years after generator functions with the yield keyword were introduced in Python 2.2, PEP 342 — Coroutines via Enhanced Generators was implemented in Python 2.5. This proposal added extra methods and functionality to generator objects, most notably the .send() method.\n",
    "\n",
    "Like .__next__(), .send() causes the generator to advance to the next yield, but it also allows the client using the generator to send data into it: whatever argument is passed to .send() becomes the value of the corresponding yield expression inside the generator function body. In other words, .send() allows two-way data exchange be‐ tween the client code and the generator — in contrast with .__next__() which only lets the client receive data from the generator.\n",
    "\n",
    "This is such a major “enhancement” that it actually changes the nature of generators: when used in this way, they become coroutines. David Beazley — probably the most prolific writer and speaker about coroutines in the Python community — warned in a famous PyCon US 2009 tutorial:\n",
    "\n",
    "• Generators produce data for iteration\n",
    "• Coroutines are consumers of data\n",
    "• To keep your brain from exploding, you don’t mix the two concepts together\n",
    "• Coroutines are not related to iteration\n",
    "• Note: There is a use of having yield produce a value in a coroutine, but it’s not tied to iteration15.\n",
    "— David Beazley\n",
    "\n",
    "A curious course on coroutines and concurrency\n",
    "I will follow Dave’s advice and close this chapter — which is really about iteration tech‐ niques — without touching send and the other features that make generators usable as coroutines. Coroutines will be covered in XXXREf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coroutines\n",
    "\n",
    "We find two main senses for the verb “to yield” in dictionaries: to produce or to give way. Both senses apply in Python when we use the yield keyword in a generator. A line such as yield item produces a value that is received by the caller of next(...), and it also gives way, suspending the execution of the generator so that the caller may proceed until it’s ready to consume another value by invoking next() again. The caller pulls values from the generator.\n",
    "\n",
    "A coroutine is syntactically like a generator: just a function with the yield keyword in its body. However, in a coroutine, yield usually appears on the right side of an expres‐ sion, e.g. datum = yield, and it may or may not produce a value — if there is no ex‐ pression after the yield keyword, the generator yields None. The coroutine may receive data from the caller, which uses .send(datum) instead of next(...) to feed the coroutine. Usually, the caller pushes values into the coroutine.\n",
    "\n",
    "It is even possible that no data goes in or out through the yield keyword. Regardless of the flow of data, yield is a control flow device that can be used to implement cooperative multi-tasking: each coroutine yields control to a central scheduler so that other corou‐ tines can be activated.\n",
    "\n",
    "When you start thinking of yield primarily in terms of control flow, you have the mindset to understand coroutines.\n",
    "Python coroutines are the product of a series of enhancements to the humble generator functions we’ve seen so far in the book. Following the evolution of coroutines in Python helps understand their features in stages of increasing functionality and complexity.\n",
    "\n",
    "After a brief overview of how generators were enable to act as a coroutine, we jump to the core of the chapter. Then we’ll see:\n",
    "\n",
    "The behavior and states of a generator operating as a coroutine.\n",
    "\n",
    "• Priming a coroutine automatically with a decorator.\n",
    "• How the caller can control a coroutine through the .close() and .throw(...) methods of the generator object.\n",
    "• How coroutines can return values upon termination.\n",
    "• Usage and semantics of the new yield from syntax.\n",
    "• A use case: coroutines for managing concurrent activities in a simulation.\n",
    "\n",
    "### How coroutines evolved from generators\n",
    "The infrastructure for coroutines appeared in PEP 342 — Coroutines via Enhanced Generators, implemented in Python 2.5 (2006): since then the yield keyword can be used in an expression, and the .send(value) method was added to the generator API. Using .send(...), the caller of the generator can post data which then becomes the value of the yield expression inside the generator function. This allows a generator to be used as a coroutine: a procedure that collaborates with the caller, yielding and receiving values from the caller.\n",
    "\n",
    "In addition to .send(...), PEP 342 also added .throw(...) and .close() methods that respectively allow the caller to throw an exception to be handled inside the generator, and to terminate it. These features are covered in the next section and in “Coroutine termination and exception handling” on page 473.\n",
    "\n",
    "The latest evolutionary step for coroutines came with PEP 380 - Syntax for Delegating to a Subgenerator, implemented in Python 3.3 (2012). PEP 380 made two syntax changes to generator functions, to make them more useful as coroutines:\n",
    "\n",
    "• A generator can now return a value; previously, providing a value to the return statement inside a generator raised a SyntaxError.\n",
    "\n",
    "• The yield from syntax enables complex generators to be refactored into smaller, nested generators while avoiding a lot of boilerplate code previously required for a generator to delegate to subgenerators.\n",
    "These latest changes will be addressed in “Returning a value from a coroutine” on page 477 and “Using yield from” on page 479.\n",
    "Let’s follow the established tradition of Fluent Python and start with some very basic facts and examples, then move into increasingly mind-bending features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> coroutine started\n",
      "-> coroutine received: 42\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-57ee1ba5443b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmy_coro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_coro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmy_coro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def simple_coroutine(): #\n",
    "    print('-> coroutine started')\n",
    "    x=yield #\n",
    "    print('-> coroutine received:', x)\n",
    "    \n",
    "my_coro = simple_coroutine()\n",
    "my_coro\n",
    "next(my_coro)\n",
    "my_coro.send(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coroutine is defined as a generator function: with yield in its body.\n",
    "\n",
    "yield is used in an expression; when the coroutine is designed just to receive data from the client it yields None — this is implicit as there is no expression to the right of the yield keyword.\n",
    "\n",
    "As usual with generators, you call the function to get a generator object back. The first call is next(...) because the generator hasn’t started so it’s not waiting\n",
    "\n",
    "in a yield and we can’t send it any data initially.\n",
    "\n",
    "This call makes the yield in the coroutine body evaluate to 42; now the coroutine\n",
    "resumes and runs until the next yield or termination.\n",
    "\n",
    "In this case, control flows off the end of the coroutine body, which prompts the\n",
    "generator machinery to raise StopIteration, as usual.\n",
    "\n",
    "A coroutine can be in one of four states. You can determine the current state using the\n",
    "inspect.getgeneratorstate(...) function which returns one of these strings: \n",
    "\n",
    "'GEN_CREATED'\n",
    "Waiting to start execution.\n",
    "\n",
    "'GEN_RUNNING'\n",
    "Currently being executed by the interpreter1\n",
    "\n",
    "'GEN_SUSPENDED'\n",
    "Currently suspended at a yield expression.\n",
    "\n",
    "'GEN_CLOSED'\n",
    "Execution has completed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coroutine can be in one of four states. You can determine the current state using the\n",
    "inspect.getgeneratorstate(...) function which returns one of these strings: 'GEN_CREATED'\n",
    "Waiting to start execution.\n",
    "'GEN_RUNNING'\n",
    "Currently being executed by the interpreter1\n",
    "'GEN_SUSPENDED'\n",
    "Currently suspended at a yield expression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking I/O and the GIL\n",
    "\n",
    "The CPython interpreter is not thread-safe internally, so it has a Global Interpreter Lock (GIL) which allows only one thread at a time to execute Python bytecodes. That’s why a single Python process usually cannot use multiple CPU cores at the same time3.\n",
    "\n",
    "When we write Python code we have no control over the GIL, but a built-in function or an extension written in C can release the GIL while running time consuming tasks. In fact, a Python library coded in C can manage the GIL, launch its own OS threads and take advantage of all available CPU cores. This complicates the code of the library con‐ siderably, and most library authors don’t do it.\n",
    "\n",
    "However, all standard library functions that perform blocking I/O release the GIL when waiting for a result from the OS. This means Python programs that are I/O bound can benefit from using threads at the Python level: while one Python thread is waiting for a response from the network, the blocked I/O function releases the GIL so another thread can run.\n",
    "That’s why David Beazley says: “Python threads are great at doing nothing4.”\n",
    "\n",
    "That’s why David Beazley says: “Python threads are great at doing nothing4.”\n",
    "Every blocking I/O function in the Python standard library re‐ leases the GIL, allowing other threads to run. The time.sleep() function also releases the GIL. Therefore, Python threads are perfectly usable in I/O bound applications, despite the GIL.\n",
    "\n",
    "Now let’s take a brief look at a simple way to work around the GIL for CPU-bound jobs using concurrent.futures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are intrigued about the GIL, start with the Python Library and Extension FAQ: Can’t we get rid of the Global Interpreter Lock?. Also worth reading are posts by Guido van Rossum and Jesse Noller (contributor of the multiprocessing package): It isn’t Easy to Remove the GIL and Python Threads and the Global Interpreter Lock. Finally, David Beazley has a detailed exploration on the inner workings of the GIL: Under‐ standing the Python GIL8. In slide #54 of the presentation, Beazley reports some alarm‐ ing results, including a 20x increase in processing time for a particular benchmark with the new GIL algorithm introduced in Python 3.2. However, Beazley apparently used an empty while True: pass to simulate CPU-bound work, and that is not realistic. The issue is not significant with real workloads, according to a comment by Antoine Pi‐ trou — who implemented the new GIL algorithm — in the bug report submitted by Beazley.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrency with asyncio\n",
    "\n",
    "Professor Imre Simon2 liked to say there are two major sins in science: using different words to mean the same thing and using one word to mean different things. If you do any research on concurrent or parallel programming you will find different definitions for “concurrency” and “parallelism”. I will adopt the informal definitions by Rob Pike, quoted above.\n",
    "\n",
    "For real parallelism you must have multiple cores. A modern laptop has 4 CPU cores but is routinely running more than 100 processes at any given time under normal, casual use. So, in practice, most processing happens concurrently and not in parallel. The computer is constantly dealing with 100+ processes, making sure each has an oppor‐ tunity to make progress, even if the CPU itself can’t do more than 4 things at once. Ten years ago we used machines which were also able to handle 100 processes concurrently, but on a single core. That’s why Rob Pike titled that talk “Concurrency is not Parallelism (it’s better).”\n",
    "\n",
    "This chapter introduces asyncio, a package that implements concurrency with corou‐ tines driven by an event loop. It’s one of the largest and most ambitious libraries ever added to Python. Guido van Rossum developed asyncio outside of the Python repos‐ itory and gave the project a code name of “Tulip\" — so you’ll see references to that flower when researching this topic online. For example, the main discussion group is still called python-tulip.\n",
    "Tulip was renamed to asyncio when it was added to the standard library in Python 3.4. It’s also compatible with Python 3.3 — you can find it on PyPI under the new official name.Becauseitusesyield fromexpressionsextensively,asyncioisincompatiblewith older versions of Python.\n",
    "\n",
    "### Thread versus coroutine: a comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
